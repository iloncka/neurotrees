{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "711869e1-3952-41dd-a392-da0ef1332ebc",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "a33a50ff",
    "execution_start": 1644072522695,
    "execution_millis": 2136,
    "deepnote_cell_type": "code"
   },
   "source": "import argparse, os, logging, random, time\nimport numpy as np\nimport math\nimport time\nimport scipy.sparse\nimport lightgbm as lgb\nimport data_helpers as dh\n\nimport sklearn.metrics\n\nimport torch\nimport torch.nn as nn\nimport torchvision\nimport torchvision.transforms as transforms\n# import tensorboardX as tbx\nfrom sklearn.utils.extmath import softmax\n\nfrom torch.autograd import Variable\nfrom torch.nn.parameter import Parameter\nfrom torch.optim import Optimizer, AdamW\nimport gc\n\n\nimport pdb\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\nif torch.cuda.is_available():\n    torch.set_default_tensor_type(torch.cuda.FloatTensor)\n    type_prefix = torch.cuda\nelse:\n    type_prefix = torch",
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "4826a482-51b1-46f6-98be-2e986c64abcb",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "4d7d990c",
    "execution_start": 1644072524841,
    "execution_millis": 7,
    "deepnote_cell_type": "code"
   },
   "source": "from importlib import reload \n\nreload(logging)\nlogger = logging.getLogger()\nlogger.setLevel(logging.INFO)\n# create file handler which logs even debug messages\nfh = logging.FileHandler('wine-100-y-one-hot-6.log')\nfh.setLevel(logging.INFO)\n# create console handler with a higher log level\nch = logging.StreamHandler()\nch.setLevel(logging.ERROR)\n# create formatter and add it to the handlers\nformatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\nch.setFormatter(formatter)\nfh.setFormatter(formatter)\n# add the handlers to logger\nlogger.addHandler(ch)\nlogger.addHandler(fh)",
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "affdfcc8-b2a8-4fbf-b86b-9fcb6ae11861",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "47cd33c8",
    "execution_start": 1644072524859,
    "execution_millis": 4,
    "deepnote_cell_type": "code"
   },
   "source": "def one_hot(y, numslot, mask=None):\n    y_tensor = y.type(type_prefix.LongTensor).reshape(-1, 1)\n    y_one_hot = torch.zeros(y_tensor.size()[0], numslot, device=device, dtype=torch.float32, requires_grad=False).scatter_(1, y_tensor, 1)\n    if mask is not None:\n        y_one_hot = y_one_hot * mask\n    y_one_hot = y_one_hot.reshape(y.shape[0], -1)\n    return y_one_hot",
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "dccdf6f2-1602-47be-b1d1-b64ae1e2a8e6",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "ff6ce09a",
    "execution_start": 1644072524875,
    "execution_millis": 3,
    "deepnote_cell_type": "code"
   },
   "source": "class BatchDense(nn.Module):\n    def __init__(self, batch, in_features, out_features, bias_init=None):\n        super(BatchDense, self).__init__()\n        self.batch = batch\n        self.in_features = in_features\n        self.out_features = out_features\n        self.weight = Parameter(torch.Tensor(batch, in_features, out_features))\n        self.bias = Parameter(torch.Tensor(batch, 1, out_features))\n        self.reset_parameters(bias_init)\n    def reset_parameters(self, bias_init=None):\n        stdv = math.sqrt(6.0 /(self.in_features + self.out_features))\n        self.weight.data.uniform_(-stdv, stdv)\n        if bias_init is not None:\n            self.bias.data = torch.from_numpy(bias_init)\n        else:\n            self.bias.data.fill_(0)\n    def forward(self, x):\n        size = x.size()\n        # Todo: avoid the swap axis\n        x = x.view(x.size(0), self.batch, -1)\n        out = x.transpose(0, 1).contiguous()\n        out = torch.baddbmm(self.bias, out, self.weight)\n        out = out.transpose(0, 1).contiguous()\n        out = out.view(x.size(0), -1)\n        return out",
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "0a328609-450a-406b-b5d7-66f028bd7aad",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "733f89a3",
    "execution_start": 1644072524901,
    "execution_millis": 3,
    "deepnote_cell_type": "code"
   },
   "source": "class GBDT2NN(nn.Module):\n    def __init__(self, input_size, used_features,\n                 tree_layers, output_w, output_b, task):\n        super(GBDT2NN, self).__init__()\n        print('Init GBDT2NN')\n        self.task = task\n        self.n_models = len(used_features)\n        self.tree_layers = tree_layers\n        n_feature = len(used_features[0])\n        used_features = np.asarray(used_features).reshape(-1)\n        self.used_features = Variable(torch.from_numpy(used_features).to(device), requires_grad=False)\n        self.relu = nn.ReLU()\n        self.sigmoid = nn.Sigmoid()\n        assert len(tree_layers) > 0\n        self.bdenses = nn.ModuleList()\n        self.bns = nn.ModuleList()\n        self.bdenses.append(BatchDense(self.n_models, n_feature, tree_layers[0]))\n        for i in range(1, len(tree_layers)):\n            self.bdenses.append(BatchDense(self.n_models, tree_layers[i-1], tree_layers[i]))\n        for i in range(len(tree_layers)-1):\n            self.bns.append(nn.BatchNorm1d(tree_layers[i] * self.n_models))\n        self.out_weight = Variable(torch.from_numpy(output_w).to(device), requires_grad=False)\n        self.out_bias = Variable(torch.from_numpy(output_b).to(device), requires_grad=False)\n        print('Init GBDT2NN succeed!')\n        if self.task == 'regression':\n            self.criterion = nn.MSELoss()\n        else:\n            self.criterion = nn.BCELoss()\n\n    def batchmul(self, x, f):\n        out = x.view(x.size(0), self.n_models, -1)\n        out = f(out)\n        out = out.view(x.size(0), -1)\n        return out\n    def lastlayer(self, x):\n        out = torch.index_select(x, dim=1, index=self.used_features)\n        for i in range(len(self.bdenses) - 1):\n            out = self.batchmul(out, self.bdenses[i])\n            out = self.bns[i](out)\n            out = self.relu(out)\n        return out\n    \n    def forward(self, x):\n        out = self.lastlayer(x.float())\n        pred = self.batchmul(out, self.bdenses[-1])\n        out = torch.addmm(self.out_bias, pred, self.out_weight)\n        if self.task != 'regression':\n            return self.sigmoid(out), pred\n        return out, pred\n\n    def emb_loss(self, emb_pred, emb_target):\n        loss_weight = torch.abs(torch.sum(self.out_weight, 1))\n        l2_loss = nn.MSELoss(reduction='none')(emb_pred, emb_target)*loss_weight\n        return torch.mean(torch.sum(l2_loss, dim=1))\n\n    def joint_loss(self, out, target, emb_pred, emb_target, ratio):\n        return (1-ratio) * self.criterion(out, target) + ratio * self.emb_loss(emb_pred, emb_target)\n\n    def true_loss(self, out, target):\n        return self.criterion(out, target)\n",
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "8a7f2c1f-a30a-4324-9122-ea88dd17fa4a",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "f27db70a",
    "execution_start": 1644072524910,
    "execution_millis": 37,
    "deepnote_cell_type": "code"
   },
   "source": "def eval_metrics(task, true, pred):\n    if task == 'binary':\n        logloss = sklearn.metrics.log_loss(true.astype(np.float64), pred.astype(np.float64))\n        auc = sklearn.metrics.roc_auc_score(true, pred)\n        # error = 1-sklearn.metrics.accuracy_score(true,(pred+0.5).astype(np.int32))\n        return (logloss, auc)#, error)\n    else:\n        mseloss = sklearn.metrics.mean_squared_error(true, pred)\n        return mseloss\n\ndef EvalTestset(test_x, test_y, model, test_batch_size, test_x_opt=None):\n    test_len = test_x.shape[0]\n    test_num_batch = math.ceil(test_len / test_batch_size)\n    sum_loss = 0.0\n    y_preds = []\n    model.eval()\n    with torch.no_grad():\n        for jdx in range(test_num_batch):\n            tst_st = jdx * test_batch_size\n            tst_ed = min(test_len, tst_st + test_batch_size)\n            inputs = torch.from_numpy(test_x[tst_st:tst_ed].astype(np.float32)).to(device)\n            if test_x_opt is not None:\n                inputs_opt = torch.from_numpy(test_x_opt[tst_st:tst_ed].astype(np.float32)).to(device)\n                outputs = model(inputs, inputs_opt)\n            else:\n                outputs = model(inputs)\n            targets = torch.from_numpy(test_y[tst_st:tst_ed]).to(device)\n            if isinstance(outputs, tuple):\n                outputs = outputs[0]\n            y_preds.append(outputs)\n            loss_tst = model.true_loss(outputs, targets).item()\n            sum_loss += (tst_ed - tst_st) * loss_tst\n    return sum_loss / test_len, np.concatenate(y_preds, 0)\n\ndef TrainWithLog(loss_dr, loss_init, loss_de, log_freq, test_freq, task, test_batch_size,                \n                train_x, train_y, \n                 train_y_opt, test_x, test_y, model, opt,\n                 epoch, batch_size, n_output, key=\"\",\n                 train_x_opt=None, test_x_opt=None):\n    # trn_writer = tf.summary.FileWriter(summaryPath+plot_title+key+\"_output/train\")\n    # tst_writer = tf.summary.FileWriter(summaryPath+plot_title+key+\"_output/test\")\n    if isinstance(test_x, scipy.sparse.csr_matrix):\n        test_x = test_x.todense()\n    train_len = train_x.shape[0]\n    global_iter = 0\n    trn_batch_size = batch_size\n    train_num_batch = math.ceil(train_len / trn_batch_size)\n    total_iterations = epoch * train_num_batch\n    start_time = time.time()\n    total_time = 0.0\n    min_loss = float(\"Inf\")\n    # min_error = float(\"Inf\")\n    max_auc = 0.0\n    for epoch in range(epoch):\n        shuffled_indices = np.random.permutation(np.arange(train_x.shape[0]))\n        Loss_trn_epoch = 0.0\n        Loss_trn_log = 0.0\n        log_st = 0\n        for local_iter in range(train_num_batch):\n            trn_st = local_iter * trn_batch_size\n            trn_ed = min(train_len, trn_st + trn_batch_size)\n            batch_trn_x = train_x[shuffled_indices[trn_st:trn_ed]]\n            if isinstance(batch_trn_x, scipy.sparse.csr_matrix):\n                batch_trn_x = batch_trn_x.todense()\n            inputs = torch.from_numpy(batch_trn_x.astype(np.float32)).to(device)\n            targets = torch.from_numpy(train_y[shuffled_indices[trn_st:trn_ed],:]).to(device)\n            model.train()\n            if train_x_opt is not None:\n                inputs_opt = torch.from_numpy(train_x_opt[shuffled_indices[trn_st:trn_ed]].astype(np.float32)).to(device)\n                outputs = model(inputs, inputs_opt)\n            else:\n                outputs = model(inputs)\n            opt.zero_grad()\n            if isinstance(outputs, tuple) and train_y_opt is not None:\n                # targets_inner = torch.from_numpy(s_train_y_opt[trn_st:trn_ed,:]).to(device)\n                targets_inner = torch.from_numpy(train_y_opt[shuffled_indices[trn_st:trn_ed],:]).to(device)\n                loss_ratio = loss_init * max(0.3,loss_dr ** (epoch // loss_de))#max(0.5, args.loss_dr ** (epoch // args.loss_de))\n                if len(outputs) == 3:\n                    loss_val = model.joint_loss(outputs[0], targets, outputs[1], targets_inner, loss_ratio, outputs[2])\n                else:\n                    loss_val = model.joint_loss(outputs[0], targets, outputs[1], targets_inner, loss_ratio)\n                loss_val.backward()\n                loss_val = model.true_loss(outputs[0], targets)\n            elif isinstance(outputs, tuple):\n                loss_val = model.true_loss(outputs[0], targets)\n                loss_val.backward()\n            else:\n                loss_val = model.true_loss(outputs, targets)\n                loss_val.backward()\n            opt.step()\n            loss_val = loss_val.item()\n            global_iter += 1\n            Loss_trn_epoch += (trn_ed - trn_st) * loss_val\n            Loss_trn_log += (trn_ed - trn_st) * loss_val\n            if global_iter % log_freq == 0:\n                print(key+\"Epoch-{:0>3d} {:>5d} Batches, Step {:>6d}, Training Loss: {:>9.6f} (AllAvg {:>9.6f})\"\n                            .format(epoch, local_iter + 1, global_iter, Loss_trn_log/(trn_ed-log_st), Loss_trn_epoch/trn_ed))\n                \n                # trn_summ = tf.Summary()\n                # trn_summ.value.add(tag=args.data+ \"/Train/Loss\", simple_value = Loss_trn_log/(trn_ed-log_st))\n                # trn_writer.add_summary(trn_summ, global_iter)\n                log_st = trn_ed\n                Loss_trn_log = 0.0\n            if global_iter % test_freq == 0 or local_iter == train_num_batch - 1:\n                if model == 'deepgbm' or model == 'd1':\n                    try:\n                        print('Alpha: '+str(model.alpha))\n                        print('Beta: '+str(model.beta))\n                    except:\n                        pass\n                # tst_summ = tf.Summary()\n                torch.cuda.empty_cache()\n                test_loss, pred_y = EvalTestset(test_x, test_y, model, test_batch_size, test_x_opt)\n                current_used_time = time.time() - start_time\n                start_time = time.time()\n                total_time += current_used_time\n                remaining_time = (total_iterations - (global_iter) ) * (total_time / (global_iter))\n                if task == 'binary':\n                    metrics = eval_metrics(task, test_y, pred_y)\n                    _, test_auc = metrics\n                    # min_error = min(min_error, test_error)\n                    max_auc = max(max_auc, test_auc)\n                    # tst_summ.value.add(tag=args.data+\"/Test/Eval/Error\", simple_value = test_error)\n                    # tst_summ.value.add(tag=args.data+\"/Test/Eval/AUC\", simple_value = test_auc)\n                    # tst_summ.value.add(tag=args.data+\"/Test/Eval/Min_Error\", simple_value = min_error)\n                    # tst_summ.value.add(tag=args.data+\"/Test/Eval/Max_AUC\", simple_value = max_auc)\n                    print(key+\"Evaluate Result:\\nEpoch-{:0>3d} {:>5d} Batches, Step {:>6d}, Testing Loss: {:>9.6f}, Testing AUC: {:8.6f}, Used Time: {:>5.1f}m, Remaining Time: {:5.1f}m\"\n                            .format(epoch, local_iter + 1, global_iter, test_loss, test_auc, total_time/60.0, remaining_time/60.0))\n                else:\n                    print(key+\"Evaluate Result:\\nEpoch-{:0>3d} {:>5d} Batches, Step {:>6d}, Testing Loss: {:>9.6f}, Used Time: {:>5.1f}m, Remaining Time: {:5.1f}m\"\n                            .format(epoch, local_iter + 1, global_iter, test_loss, total_time/60.0, remaining_time/60.0))\n                min_loss = min(min_loss, test_loss)\n                # tst_summ.value.add(tag=args.data+\"/Test/Loss\", simple_value = test_loss)\n                # tst_summ.value.add(tag=args.data+\"/Test/Min_Loss\", simple_value = min_loss)\n                print(\"-------------------------------------------------------------------------------\")\n                # tst_writer.add_summary(tst_summ, global_iter)\n                # tst_writer.flush()\n        print(\"Best Metric: %s\"%(str(max_auc) if task=='binary' else str(min_loss)))\n        print(\"####################################################################################\")\n    print(\"Final Best Metric: %s\"%(str(max_auc) if task=='binary' else str(min_loss)))\n    return min_loss        \n\ndef GetEmbPred(model, fun, X, test_batch_size):\n    model.eval()\n    tst_len = X.shape[0]\n    test_num_batch = math.ceil(tst_len / test_batch_size)\n    y_preds = []\n    with torch.no_grad():\n        for jdx in range(test_num_batch):\n            tst_st = jdx * test_batch_size\n            tst_ed = min(tst_len, tst_st + test_batch_size)\n            inputs = torch.from_numpy(X[tst_st:tst_ed]).to(device)\n            t_preds = fun(inputs).data.cpu().numpy()\n            y_preds.append(t_preds)\n        y_preds = np.concatenate(y_preds, 0)\n    return y_preds\n",
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "4780bb6f-8527-4ee1-9c5c-76419f81031a",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "7ddb1838",
    "execution_start": 1644072524997,
    "execution_millis": 0,
    "deepnote_cell_type": "code"
   },
   "source": "HOME_DIR = os.getcwd()\nDATA_DIR = os.path.join(HOME_DIR, 'data')",
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "3b80205a-e0fe-4e97-858f-ad6f05c8d155",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "15d6e06e",
    "execution_start": 1644072524998,
    "execution_millis": 0,
    "deepnote_output_heights": [
     403
    ],
    "deepnote_cell_type": "code"
   },
   "source": "num_data = dh.load_data('/work/neurotrees/articles code reproduction/DeepGBM/data/data_offline_num')",
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "a7ba9077-b52d-484f-b60f-ef2ca8044319",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "14a37530",
    "execution_start": 1644072524999,
    "execution_millis": 0,
    "deepnote_cell_type": "code"
   },
   "source": "train_x, train_y, test_x, test_y = num_data",
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "c719697e-d8d1-4aa6-b808-b871d503f9c1",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "df365924",
    "execution_start": 1644072524999,
    "execution_millis": 3,
    "deepnote_output_heights": [
     21
    ],
    "deepnote_cell_type": "code"
   },
   "source": "train_x.shape",
   "execution_count": 10,
   "outputs": [
    {
     "output_type": "execute_result",
     "execution_count": 10,
     "data": {
      "text/plain": "(3918, 12)"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "df71ad47-63c4-47aa-8ad7-0661b56eff69",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "4b73da7b",
    "execution_start": 1644072525035,
    "execution_millis": 278507851,
    "deepnote_output_heights": [
     21
    ],
    "deepnote_cell_type": "code"
   },
   "source": "type(train_x)",
   "execution_count": 11,
   "outputs": [
    {
     "output_type": "execute_result",
     "execution_count": 11,
     "data": {
      "text/plain": "numpy.ndarray"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "72e8618a-9dcc-4012-a18f-fb2bb3d0707f",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "18385d78",
    "execution_start": 1644072525036,
    "execution_millis": 7,
    "deepnote_cell_type": "code"
   },
   "source": "import pickle\nwith open('n_models_wine_100.pickle', 'rb') as f:\n    # Pickle using the highest protocol available.\n    n_models = pickle.load(f)\n    \nwith open('max_ntree_per_split_wine_100.pickle', 'rb') as f:\n    # Pickle using the highest protocol available.\n    max_ntree_per_split = pickle.load(f)\n    \nwith open('group_average_wine_100.pickle', 'rb') as f:\n    # Pickle using the highest protocol available.\n    group_average = pickle.load(f)\n\nwith open('leaf_preds_wine_100.pickle', 'rb') as f:\n    # Pickle using the highest protocol available.\n    leaf_preds = pickle.load(f)\n    \nwith open('test_leaf_preds_wine_100.pickle', 'rb') as f:\n    # Pickle using the highest protocol available.\n    test_leaf_preds = pickle.load(f)\n    \nwith open('tree_outputs_wine_100.pickle', 'rb') as f:\n    # Pickle using the highest protocol available.\n    tree_outputs = pickle.load(f) ",
   "execution_count": 12,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "458052bb-dae1-4cc2-be8e-543de1b19cdf",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "c3106ec1",
    "execution_start": 1644072525037,
    "execution_millis": 0,
    "deepnote_cell_type": "code"
   },
   "source": "with open('used_features_wine_100.pickle', 'rb') as f:\n    # Pickle using the highest protocol available.\n    used_features = pickle.load(f)",
   "execution_count": 13,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "8a61b799-8d75-47c2-83ff-da75b3ffa939",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "f030681e",
    "execution_start": 1644072525039,
    "execution_millis": 14,
    "deepnote_cell_type": "code"
   },
   "source": "import pickle\nwith open('train_embs_wine_100.pickle', 'rb') as f:\n    # Pickle using the highest protocol available.\n    train_embs = pickle.load(f)\n    \nwith open('output_w_wine_100.pickle', 'rb') as f:\n    # Pickle using the highest protocol available.\n    output_w = pickle.load(f)\n    \nwith open('output_b_wine_100.pickle', 'rb') as f:\n    # Pickle using the highest protocol available.\n    output_b = pickle.load(f)",
   "execution_count": 14,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "4707a252-543c-4bc1-b387-eaa2d15658bc",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "9e02d033",
    "execution_start": 1644072525106,
    "execution_millis": 74364,
    "deepnote_cell_type": "code"
   },
   "source": "\nloss_init = 1.0\nloss_dr = 0.7\nloss_de = 2\nlog_freq = 500\ntest_freq = 300\nkey = \"\"\nseeds = [1,2] #,3,4,5 \ntree_layers = [100,100,100,50]\nlr = 1e-3\nl2_reg = 1e-6\nmax_epoch = 100\nbatch_size = 512\ntest_batch_size = 100 \nembsize = 20\ntask = \"regression\"\n\n\nn_output = train_y.shape[1]\n\n# tree_layers = [int(x) for x in tree_layers.split(',')]\ntree_layers.append(embsize)\n\nconcate_train_x = np.concatenate([train_x, np.zeros((train_x.shape[0],1), dtype=np.float32)], axis=-1)\nconcate_test_x = np.concatenate([test_x, np.zeros((test_x.shape[0],1), dtype=np.float32)], axis=-1)\ntree_outputs = train_embs\nfor seed in seeds:\n    np.random.seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    gbdt2nn_model = GBDT2NN(concate_train_x.shape[1], \n                            np.asarray(used_features,dtype=np.int64),\n                            tree_layers,\n                            output_w, output_b, task).to(device)\n    opt = AdamW(gbdt2nn_model.parameters(), lr=lr, weight_decay=l2_reg, amsgrad=False)\n\n    TrainWithLog( loss_dr, loss_init, loss_de, log_freq, test_freq, task, test_batch_size,\n                 concate_train_x, train_y, tree_outputs,\n                    concate_test_x, test_y, gbdt2nn_model, opt,\n                    max_epoch, batch_size, n_output, key)\n    _,pred_y = EvalTestset(concate_test_x, test_y, gbdt2nn_model, test_batch_size)\n    metric = eval_metrics(task, test_y, pred_y)\n    print('Final metrics: %s'%str(metric))",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "text": "Evaluate Result:\nEpoch-003     8 Batches, Step     32, Testing Loss:  0.863902, Used Time:   0.0m, Remaining Time:   0.6m\n-------------------------------------------------------------------------------\nBest Metric: 0.8639023973017322\n####################################################################################\nEvaluate Result:\nEpoch-004     8 Batches, Step     40, Testing Loss:  0.739034, Used Time:   0.0m, Remaining Time:   0.6m\n-------------------------------------------------------------------------------\nBest Metric: 0.7390338547375738\n####################################################################################\nEvaluate Result:\nEpoch-005     8 Batches, Step     48, Testing Loss:  0.924381, Used Time:   0.0m, Remaining Time:   0.6m\n-------------------------------------------------------------------------------\nBest Metric: 0.7390338547375738\n####################################################################################\nEvaluate Result:\nEpoch-006     8 Batches, Step     56, Testing Loss:  0.309328, Used Time:   0.0m, Remaining Time:   0.6m\n-------------------------------------------------------------------------------\nBest Metric: 0.3093278991932772\n####################################################################################\nEvaluate Result:\nEpoch-007     8 Batches, Step     64, Testing Loss:  0.380311, Used Time:   0.0m, Remaining Time:   0.6m\n-------------------------------------------------------------------------------\nBest Metric: 0.3093278991932772\n####################################################################################\nEvaluate Result:\nEpoch-008     8 Batches, Step     72, Testing Loss:  0.257831, Used Time:   0.1m, Remaining Time:   0.6m\n-------------------------------------------------------------------------------\nBest Metric: 0.25783065812928335\n####################################################################################\nEvaluate Result:\nEpoch-009     8 Batches, Step     80, Testing Loss:  0.244708, Used Time:   0.1m, Remaining Time:   0.6m\n-------------------------------------------------------------------------------\nBest Metric: 0.2447079024752792\n####################################################################################\nEvaluate Result:\nEpoch-010     8 Batches, Step     88, Testing Loss:  0.224692, Used Time:   0.1m, Remaining Time:   0.6m\n-------------------------------------------------------------------------------\nBest Metric: 0.22469185323131327\n####################################################################################\nEvaluate Result:\nEpoch-011     8 Batches, Step     96, Testing Loss:  0.206344, Used Time:   0.1m, Remaining Time:   0.6m\n-------------------------------------------------------------------------------\nBest Metric: 0.2063435830023824\n####################################################################################\nEvaluate Result:\nEpoch-012     8 Batches, Step    104, Testing Loss:  0.205114, Used Time:   0.1m, Remaining Time:   0.5m\n-------------------------------------------------------------------------------\nBest Metric: 0.20511374059988527\n####################################################################################\nEvaluate Result:\nEpoch-013     8 Batches, Step    112, Testing Loss:  0.193056, Used Time:   0.1m, Remaining Time:   0.5m\n-------------------------------------------------------------------------------\nBest Metric: 0.19305578634446982\n####################################################################################\nEvaluate Result:\nEpoch-014     8 Batches, Step    120, Testing Loss:  0.204507, Used Time:   0.1m, Remaining Time:   0.5m\n-------------------------------------------------------------------------------\nBest Metric: 0.19305578634446982\n####################################################################################\nEvaluate Result:\nEpoch-015     8 Batches, Step    128, Testing Loss:  0.203145, Used Time:   0.1m, Remaining Time:   0.5m\n-------------------------------------------------------------------------------\nBest Metric: 0.19305578634446982\n####################################################################################\nEvaluate Result:\nEpoch-016     8 Batches, Step    136, Testing Loss:  0.214878, Used Time:   0.1m, Remaining Time:   0.5m\n-------------------------------------------------------------------------------\nBest Metric: 0.19305578634446982\n####################################################################################\nEvaluate Result:\nEpoch-017     8 Batches, Step    144, Testing Loss:  0.223571, Used Time:   0.1m, Remaining Time:   0.5m\n-------------------------------------------------------------------------------\nBest Metric: 0.19305578634446982\n####################################################################################\nEvaluate Result:\nEpoch-018     8 Batches, Step    152, Testing Loss:  0.181856, Used Time:   0.1m, Remaining Time:   0.5m\n-------------------------------------------------------------------------------\nBest Metric: 0.18185554201505622\n####################################################################################\nEvaluate Result:\nEpoch-019     8 Batches, Step    160, Testing Loss:  0.176115, Used Time:   0.1m, Remaining Time:   0.5m\n-------------------------------------------------------------------------------\nBest Metric: 0.17611463048628398\n####################################################################################\nEvaluate Result:\nEpoch-020     8 Batches, Step    168, Testing Loss:  0.216096, Used Time:   0.1m, Remaining Time:   0.5m\n-------------------------------------------------------------------------------\nBest Metric: 0.17611463048628398\n####################################################################################\nEvaluate Result:\nEpoch-021     8 Batches, Step    176, Testing Loss:  0.180939, Used Time:   0.1m, Remaining Time:   0.5m\n-------------------------------------------------------------------------------\nBest Metric: 0.17611463048628398\n####################################################################################\nEvaluate Result:\nEpoch-022     8 Batches, Step    184, Testing Loss:  0.184677, Used Time:   0.1m, Remaining Time:   0.5m\n-------------------------------------------------------------------------------\nBest Metric: 0.17611463048628398\n####################################################################################\nEvaluate Result:\nEpoch-023     8 Batches, Step    192, Testing Loss:  0.184417, Used Time:   0.1m, Remaining Time:   0.5m\n-------------------------------------------------------------------------------\nBest Metric: 0.17611463048628398\n####################################################################################\nEvaluate Result:\nEpoch-024     8 Batches, Step    200, Testing Loss:  0.187664, Used Time:   0.2m, Remaining Time:   0.5m\n-------------------------------------------------------------------------------\nBest Metric: 0.17611463048628398\n####################################################################################\nEvaluate Result:\nEpoch-025     8 Batches, Step    208, Testing Loss:  0.182551, Used Time:   0.2m, Remaining Time:   0.5m\n-------------------------------------------------------------------------------\nBest Metric: 0.17611463048628398\n####################################################################################\nEvaluate Result:\nEpoch-026     8 Batches, Step    216, Testing Loss:  0.184003, Used Time:   0.2m, Remaining Time:   0.5m\n-------------------------------------------------------------------------------\nBest Metric: 0.17611463048628398\n####################################################################################\nEvaluate Result:\nEpoch-027     8 Batches, Step    224, Testing Loss:  0.192540, Used Time:   0.2m, Remaining Time:   0.4m\n-------------------------------------------------------------------------------\nBest Metric: 0.17611463048628398\n####################################################################################\nEvaluate Result:\nEpoch-028     8 Batches, Step    232, Testing Loss:  0.179782, Used Time:   0.2m, Remaining Time:   0.4m\n-------------------------------------------------------------------------------\nBest Metric: 0.17611463048628398\n####################################################################################\nEvaluate Result:\nEpoch-029     8 Batches, Step    240, Testing Loss:  0.225991, Used Time:   0.2m, Remaining Time:   0.4m\n-------------------------------------------------------------------------------\nBest Metric: 0.17611463048628398\n####################################################################################\nEvaluate Result:\nEpoch-030     8 Batches, Step    248, Testing Loss:  0.162878, Used Time:   0.2m, Remaining Time:   0.4m\n-------------------------------------------------------------------------------\nBest Metric: 0.1628775287951742\n####################################################################################\nEvaluate Result:\nEpoch-031     8 Batches, Step    256, Testing Loss:  0.180940, Used Time:   0.2m, Remaining Time:   0.4m\n-------------------------------------------------------------------------------\nBest Metric: 0.1628775287951742\n####################################################################################\nEvaluate Result:\nEpoch-032     8 Batches, Step    264, Testing Loss:  0.196263, Used Time:   0.2m, Remaining Time:   0.4m\n-------------------------------------------------------------------------------\nBest Metric: 0.1628775287951742\n####################################################################################\nEvaluate Result:\nEpoch-033     8 Batches, Step    272, Testing Loss:  0.163815, Used Time:   0.2m, Remaining Time:   0.4m\n-------------------------------------------------------------------------------\nBest Metric: 0.1628775287951742\n####################################################################################\nEvaluate Result:\nEpoch-034     8 Batches, Step    280, Testing Loss:  0.162079, Used Time:   0.2m, Remaining Time:   0.4m\n-------------------------------------------------------------------------------\nBest Metric: 0.16207920151705646\n####################################################################################\nEvaluate Result:\nEpoch-035     8 Batches, Step    288, Testing Loss:  0.175736, Used Time:   0.2m, Remaining Time:   0.4m\n-------------------------------------------------------------------------------\nBest Metric: 0.16207920151705646\n####################################################################################\nEvaluate Result:\nEpoch-036     8 Batches, Step    296, Testing Loss:  0.175520, Used Time:   0.2m, Remaining Time:   0.4m\n-------------------------------------------------------------------------------\nBest Metric: 0.16207920151705646\n####################################################################################\nEvaluate Result:\nEpoch-037     4 Batches, Step    300, Testing Loss:  0.153681, Used Time:   0.2m, Remaining Time:   0.4m\n-------------------------------------------------------------------------------\nEvaluate Result:\nEpoch-037     8 Batches, Step    304, Testing Loss:  0.182573, Used Time:   0.2m, Remaining Time:   0.4m\n-------------------------------------------------------------------------------\nBest Metric: 0.15368122668290624\n####################################################################################\nEvaluate Result:\nEpoch-038     8 Batches, Step    312, Testing Loss:  0.154029, Used Time:   0.2m, Remaining Time:   0.4m\n-------------------------------------------------------------------------------\nBest Metric: 0.15368122668290624\n####################################################################################\nEvaluate Result:\nEpoch-039     8 Batches, Step    320, Testing Loss:  0.171910, Used Time:   0.3m, Remaining Time:   0.4m\n-------------------------------------------------------------------------------\nBest Metric: 0.15368122668290624\n####################################################################################\nEvaluate Result:\nEpoch-040     8 Batches, Step    328, Testing Loss:  0.165535, Used Time:   0.3m, Remaining Time:   0.4m\n-------------------------------------------------------------------------------\nBest Metric: 0.15368122668290624\n####################################################################################\nEvaluate Result:\nEpoch-041     8 Batches, Step    336, Testing Loss:  0.149807, Used Time:   0.3m, Remaining Time:   0.4m\n-------------------------------------------------------------------------------\nBest Metric: 0.14980666187344766\n####################################################################################\nEvaluate Result:\nEpoch-042     8 Batches, Step    344, Testing Loss:  0.182138, Used Time:   0.3m, Remaining Time:   0.4m\n-------------------------------------------------------------------------------\nBest Metric: 0.14980666187344766\n####################################################################################\nEvaluate Result:\nEpoch-043     8 Batches, Step    352, Testing Loss:  0.154294, Used Time:   0.3m, Remaining Time:   0.4m\n-------------------------------------------------------------------------------\nBest Metric: 0.14980666187344766\n####################################################################################\nEvaluate Result:\nEpoch-044     8 Batches, Step    360, Testing Loss:  0.166140, Used Time:   0.3m, Remaining Time:   0.3m\n-------------------------------------------------------------------------------\nBest Metric: 0.14980666187344766\n####################################################################################\nEvaluate Result:\nEpoch-045     8 Batches, Step    368, Testing Loss:  0.169092, Used Time:   0.3m, Remaining Time:   0.3m\n-------------------------------------------------------------------------------\nBest Metric: 0.14980666187344766\n####################################################################################\nEvaluate Result:\nEpoch-046     8 Batches, Step    376, Testing Loss:  0.170066, Used Time:   0.3m, Remaining Time:   0.3m\n-------------------------------------------------------------------------------\nBest Metric: 0.14980666187344766\n####################################################################################\nEvaluate Result:\nEpoch-047     8 Batches, Step    384, Testing Loss:  0.154122, Used Time:   0.3m, Remaining Time:   0.3m\n-------------------------------------------------------------------------------\nBest Metric: 0.14980666187344766\n####################################################################################\nEvaluate Result:\nEpoch-048     8 Batches, Step    392, Testing Loss:  0.157082, Used Time:   0.3m, Remaining Time:   0.3m\n-------------------------------------------------------------------------------\nBest Metric: 0.14980666187344766\n####################################################################################\nEvaluate Result:\nEpoch-049     8 Batches, Step    400, Testing Loss:  0.150723, Used Time:   0.3m, Remaining Time:   0.3m\n-------------------------------------------------------------------------------\nBest Metric: 0.14980666187344766\n####################################################################################\nEvaluate Result:\nEpoch-050     8 Batches, Step    408, Testing Loss:  0.159023, Used Time:   0.3m, Remaining Time:   0.3m\n-------------------------------------------------------------------------------\nBest Metric: 0.14980666187344766\n####################################################################################\nEvaluate Result:\nEpoch-051     8 Batches, Step    416, Testing Loss:  0.166250, Used Time:   0.3m, Remaining Time:   0.3m\n-------------------------------------------------------------------------------\nBest Metric: 0.14980666187344766\n####################################################################################\nEvaluate Result:\nEpoch-052     8 Batches, Step    424, Testing Loss:  0.182887, Used Time:   0.3m, Remaining Time:   0.3m\n-------------------------------------------------------------------------------\nBest Metric: 0.14980666187344766\n####################################################################################\nEvaluate Result:\nEpoch-053     8 Batches, Step    432, Testing Loss:  0.175566, Used Time:   0.3m, Remaining Time:   0.3m\n-------------------------------------------------------------------------------\nBest Metric: 0.14980666187344766\n####################################################################################\nEvaluate Result:\nEpoch-054     8 Batches, Step    440, Testing Loss:  0.197016, Used Time:   0.3m, Remaining Time:   0.3m\n-------------------------------------------------------------------------------\nBest Metric: 0.14980666187344766\n####################################################################################\nEvaluate Result:\nEpoch-055     8 Batches, Step    448, Testing Loss:  0.180363, Used Time:   0.3m, Remaining Time:   0.3m\n-------------------------------------------------------------------------------\nBest Metric: 0.14980666187344766\n####################################################################################\nEvaluate Result:\nEpoch-056     8 Batches, Step    456, Testing Loss:  0.178552, Used Time:   0.4m, Remaining Time:   0.3m\n-------------------------------------------------------------------------------\nBest Metric: 0.14980666187344766\n####################################################################################\nEvaluate Result:\nEpoch-057     8 Batches, Step    464, Testing Loss:  0.164609, Used Time:   0.4m, Remaining Time:   0.3m\n-------------------------------------------------------------------------------\nBest Metric: 0.14980666187344766\n####################################################################################\nEvaluate Result:\nEpoch-058     8 Batches, Step    472, Testing Loss:  0.160878, Used Time:   0.4m, Remaining Time:   0.3m\n-------------------------------------------------------------------------------\nBest Metric: 0.14980666187344766\n####################################################################################\nEvaluate Result:\nEpoch-059     8 Batches, Step    480, Testing Loss:  0.172493, Used Time:   0.4m, Remaining Time:   0.2m\n-------------------------------------------------------------------------------\nBest Metric: 0.14980666187344766\n####################################################################################\nEvaluate Result:\nEpoch-060     8 Batches, Step    488, Testing Loss:  0.177978, Used Time:   0.4m, Remaining Time:   0.2m\n-------------------------------------------------------------------------------\nBest Metric: 0.14980666187344766\n####################################################################################\nEvaluate Result:\nEpoch-061     8 Batches, Step    496, Testing Loss:  0.166455, Used Time:   0.4m, Remaining Time:   0.2m\n-------------------------------------------------------------------------------\nBest Metric: 0.14980666187344766\n####################################################################################\nEpoch-062     4 Batches, Step    500, Training Loss:  0.091683 (AllAvg  0.091683)\nEvaluate Result:\nEpoch-062     8 Batches, Step    504, Testing Loss:  0.167783, Used Time:   0.4m, Remaining Time:   0.2m\n-------------------------------------------------------------------------------\nBest Metric: 0.14980666187344766\n####################################################################################\nEvaluate Result:\nEpoch-063     8 Batches, Step    512, Testing Loss:  0.169996, Used Time:   0.4m, Remaining Time:   0.2m\n-------------------------------------------------------------------------------\nBest Metric: 0.14980666187344766\n####################################################################################\nEvaluate Result:\nEpoch-064     8 Batches, Step    520, Testing Loss:  0.196648, Used Time:   0.4m, Remaining Time:   0.2m\n-------------------------------------------------------------------------------\nBest Metric: 0.14980666187344766\n####################################################################################\nEvaluate Result:\nEpoch-065     8 Batches, Step    528, Testing Loss:  0.173940, Used Time:   0.4m, Remaining Time:   0.2m\n-------------------------------------------------------------------------------\nBest Metric: 0.14980666187344766\n####################################################################################\nEvaluate Result:\nEpoch-066     8 Batches, Step    536, Testing Loss:  0.192355, Used Time:   0.4m, Remaining Time:   0.2m\n-------------------------------------------------------------------------------\nBest Metric: 0.14980666187344766\n####################################################################################\nEvaluate Result:\nEpoch-067     8 Batches, Step    544, Testing Loss:  0.213770, Used Time:   0.4m, Remaining Time:   0.2m\n-------------------------------------------------------------------------------\nBest Metric: 0.14980666187344766\n####################################################################################\nEvaluate Result:\nEpoch-068     8 Batches, Step    552, Testing Loss:  0.190775, Used Time:   0.4m, Remaining Time:   0.2m\n-------------------------------------------------------------------------------\nBest Metric: 0.14980666187344766\n####################################################################################\nEvaluate Result:\nEpoch-069     8 Batches, Step    560, Testing Loss:  0.167359, Used Time:   0.4m, Remaining Time:   0.2m\n-------------------------------------------------------------------------------\nBest Metric: 0.14980666187344766\n####################################################################################\nEvaluate Result:\nEpoch-070     8 Batches, Step    568, Testing Loss:  0.173174, Used Time:   0.4m, Remaining Time:   0.2m\n-------------------------------------------------------------------------------\nBest Metric: 0.14980666187344766\n####################################################################################\nEvaluate Result:\nEpoch-071     8 Batches, Step    576, Testing Loss:  0.163636, Used Time:   0.4m, Remaining Time:   0.2m\n-------------------------------------------------------------------------------\nBest Metric: 0.14980666187344766\n####################################################################################\nEvaluate Result:\nEpoch-072     8 Batches, Step    584, Testing Loss:  0.201779, Used Time:   0.5m, Remaining Time:   0.2m\n-------------------------------------------------------------------------------\nBest Metric: 0.14980666187344766\n####################################################################################\nEvaluate Result:\nEpoch-073     8 Batches, Step    592, Testing Loss:  0.176275, Used Time:   0.5m, Remaining Time:   0.2m\n-------------------------------------------------------------------------------\nBest Metric: 0.14980666187344766\n####################################################################################\nEvaluate Result:\nEpoch-074     8 Batches, Step    600, Testing Loss:  0.196908, Used Time:   0.5m, Remaining Time:   0.2m\n-------------------------------------------------------------------------------\nBest Metric: 0.14980666187344766\n####################################################################################\nEvaluate Result:\nEpoch-075     8 Batches, Step    608, Testing Loss:  0.161898, Used Time:   0.5m, Remaining Time:   0.1m\n-------------------------------------------------------------------------------\nBest Metric: 0.14980666187344766\n####################################################################################\nEvaluate Result:\nEpoch-076     8 Batches, Step    616, Testing Loss:  0.165928, Used Time:   0.5m, Remaining Time:   0.1m\n-------------------------------------------------------------------------------\nBest Metric: 0.14980666187344766\n####################################################################################\nEvaluate Result:\nEpoch-077     8 Batches, Step    624, Testing Loss:  0.221635, Used Time:   0.5m, Remaining Time:   0.1m\n-------------------------------------------------------------------------------\nBest Metric: 0.14980666187344766\n####################################################################################\nEvaluate Result:\nEpoch-078     8 Batches, Step    632, Testing Loss:  0.207642, Used Time:   0.5m, Remaining Time:   0.1m\n-------------------------------------------------------------------------------\nBest Metric: 0.14980666187344766\n####################################################################################\nEvaluate Result:\nEpoch-079     8 Batches, Step    640, Testing Loss:  0.203546, Used Time:   0.5m, Remaining Time:   0.1m\n-------------------------------------------------------------------------------\nBest Metric: 0.14980666187344766\n####################################################################################\nEvaluate Result:\nEpoch-080     8 Batches, Step    648, Testing Loss:  0.208357, Used Time:   0.5m, Remaining Time:   0.1m\n-------------------------------------------------------------------------------\nBest Metric: 0.14980666187344766\n####################################################################################\nEvaluate Result:\nEpoch-081     8 Batches, Step    656, Testing Loss:  0.203661, Used Time:   0.5m, Remaining Time:   0.1m\n-------------------------------------------------------------------------------\nBest Metric: 0.14980666187344766\n####################################################################################\nEvaluate Result:\nEpoch-082     8 Batches, Step    664, Testing Loss:  0.160611, Used Time:   0.5m, Remaining Time:   0.1m\n-------------------------------------------------------------------------------\nBest Metric: 0.14980666187344766\n####################################################################################\nEvaluate Result:\nEpoch-083     8 Batches, Step    672, Testing Loss:  0.166075, Used Time:   0.5m, Remaining Time:   0.1m\n-------------------------------------------------------------------------------\nBest Metric: 0.14980666187344766\n####################################################################################\nEvaluate Result:\nEpoch-084     8 Batches, Step    680, Testing Loss:  0.188667, Used Time:   0.5m, Remaining Time:   0.1m\n-------------------------------------------------------------------------------\nBest Metric: 0.14980666187344766\n####################################################################################\nEvaluate Result:\nEpoch-085     8 Batches, Step    688, Testing Loss:  0.180194, Used Time:   0.5m, Remaining Time:   0.1m\n-------------------------------------------------------------------------------\nBest Metric: 0.14980666187344766\n####################################################################################\nEvaluate Result:\nEpoch-086     8 Batches, Step    696, Testing Loss:  0.189951, Used Time:   0.5m, Remaining Time:   0.1m\n-------------------------------------------------------------------------------\nBest Metric: 0.14980666187344766\n####################################################################################\nEvaluate Result:\nEpoch-087     8 Batches, Step    704, Testing Loss:  0.202636, Used Time:   0.5m, Remaining Time:   0.1m\n-------------------------------------------------------------------------------\nBest Metric: 0.14980666187344766\n####################################################################################\nEvaluate Result:\nEpoch-088     8 Batches, Step    712, Testing Loss:  0.179586, Used Time:   0.6m, Remaining Time:   0.1m\n-------------------------------------------------------------------------------\nBest Metric: 0.14980666187344766\n####################################################################################\nEvaluate Result:\nEpoch-089     8 Batches, Step    720, Testing Loss:  0.186964, Used Time:   0.6m, Remaining Time:   0.1m\n-------------------------------------------------------------------------------\nBest Metric: 0.14980666187344766\n####################################################################################\nEvaluate Result:\nEpoch-090     8 Batches, Step    728, Testing Loss:  0.197377, Used Time:   0.6m, Remaining Time:   0.1m\n-------------------------------------------------------------------------------\nBest Metric: 0.14980666187344766\n####################################################################################\nEvaluate Result:\nEpoch-091     8 Batches, Step    736, Testing Loss:  0.184731, Used Time:   0.6m, Remaining Time:   0.0m\n-------------------------------------------------------------------------------\nBest Metric: 0.14980666187344766\n####################################################################################\nEvaluate Result:\nEpoch-092     8 Batches, Step    744, Testing Loss:  0.171796, Used Time:   0.6m, Remaining Time:   0.0m\n-------------------------------------------------------------------------------\nBest Metric: 0.14980666187344766\n####################################################################################\nEvaluate Result:\nEpoch-093     8 Batches, Step    752, Testing Loss:  0.175083, Used Time:   0.6m, Remaining Time:   0.0m\n-------------------------------------------------------------------------------\nBest Metric: 0.14980666187344766\n####################################################################################\nEvaluate Result:\nEpoch-094     8 Batches, Step    760, Testing Loss:  0.212979, Used Time:   0.6m, Remaining Time:   0.0m\n-------------------------------------------------------------------------------\nBest Metric: 0.14980666187344766\n####################################################################################\nEvaluate Result:\nEpoch-095     8 Batches, Step    768, Testing Loss:  0.167142, Used Time:   0.6m, Remaining Time:   0.0m\n-------------------------------------------------------------------------------\nBest Metric: 0.14980666187344766\n####################################################################################\nEvaluate Result:\nEpoch-096     8 Batches, Step    776, Testing Loss:  0.189808, Used Time:   0.6m, Remaining Time:   0.0m\n-------------------------------------------------------------------------------\nBest Metric: 0.14980666187344766\n####################################################################################\nEvaluate Result:\nEpoch-097     8 Batches, Step    784, Testing Loss:  0.200804, Used Time:   0.6m, Remaining Time:   0.0m\n-------------------------------------------------------------------------------\nBest Metric: 0.14980666187344766\n####################################################################################\nEvaluate Result:\nEpoch-098     8 Batches, Step    792, Testing Loss:  0.173039, Used Time:   0.6m, Remaining Time:   0.0m\n-------------------------------------------------------------------------------\nBest Metric: 0.14980666187344766\n####################################################################################\nEvaluate Result:\nEpoch-099     8 Batches, Step    800, Testing Loss:  0.177880, Used Time:   0.6m, Remaining Time:   0.0m\n-------------------------------------------------------------------------------\nBest Metric: 0.14980666187344766\n####################################################################################\nFinal Best Metric: 0.14980666187344766\nFinal metrics: 0.17788035\nInit GBDT2NN\nInit GBDT2NN succeed!\nEvaluate Result:\nEpoch-000     8 Batches, Step      8, Testing Loss: 27.239537, Used Time:   0.0m, Remaining Time:   0.6m\n-------------------------------------------------------------------------------\nBest Metric: 27.239536674655213\n####################################################################################\nEvaluate Result:\nEpoch-001     8 Batches, Step     16, Testing Loss: 27.137855, Used Time:   0.0m, Remaining Time:   0.6m\n-------------------------------------------------------------------------------\nBest Metric: 27.137855296232264\n####################################################################################\nEvaluate Result:\nEpoch-002     8 Batches, Step     24, Testing Loss:  6.416927, Used Time:   0.0m, Remaining Time:   0.6m\n-------------------------------------------------------------------------------\nBest Metric: 6.416927298721002\n####################################################################################\nEvaluate Result:\nEpoch-003     8 Batches, Step     32, Testing Loss:  0.912329, Used Time:   0.0m, Remaining Time:   0.6m\n-------------------------------------------------------------------------------\nBest Metric: 0.9123287699660476\n####################################################################################\nEvaluate Result:\nEpoch-004     8 Batches, Step     40, Testing Loss:  1.137142, Used Time:   0.0m, Remaining Time:   0.6m\n-------------------------------------------------------------------------------\nBest Metric: 0.9123287699660476\n####################################################################################\nEvaluate Result:\nEpoch-005     8 Batches, Step     48, Testing Loss:  0.965206, Used Time:   0.0m, Remaining Time:   0.6m\n-------------------------------------------------------------------------------\nBest Metric: 0.9123287699660476\n####################################################################################\nEvaluate Result:\nEpoch-006     8 Batches, Step     56, Testing Loss:  0.337943, Used Time:   0.0m, Remaining Time:   0.6m\n-------------------------------------------------------------------------------\nBest Metric: 0.3379425886942416\n####################################################################################\nEvaluate Result:\nEpoch-007     8 Batches, Step     64, Testing Loss:  0.532209, Used Time:   0.0m, Remaining Time:   0.6m\n-------------------------------------------------------------------------------\nBest Metric: 0.3379425886942416\n####################################################################################\nEvaluate Result:\nEpoch-008     8 Batches, Step     72, Testing Loss:  0.300238, Used Time:   0.1m, Remaining Time:   0.6m\n-------------------------------------------------------------------------------\nBest Metric: 0.30023787307495975\n####################################################################################\nEvaluate Result:\nEpoch-009     8 Batches, Step     80, Testing Loss:  0.301739, Used Time:   0.1m, Remaining Time:   0.6m\n-------------------------------------------------------------------------------\nBest Metric: 0.30023787307495975\n####################################################################################\nEvaluate Result:\nEpoch-010     8 Batches, Step     88, Testing Loss:  0.271224, Used Time:   0.1m, Remaining Time:   0.6m\n-------------------------------------------------------------------------------\nBest Metric: 0.27122398146561216\n####################################################################################\nEvaluate Result:\nEpoch-011     8 Batches, Step     96, Testing Loss:  0.228603, Used Time:   0.1m, Remaining Time:   0.5m\n-------------------------------------------------------------------------------\nBest Metric: 0.22860328032045948\n####################################################################################\nEvaluate Result:\nEpoch-012     8 Batches, Step    104, Testing Loss:  0.268025, Used Time:   0.1m, Remaining Time:   0.5m\n-------------------------------------------------------------------------------\nBest Metric: 0.22860328032045948\n####################################################################################\nEvaluate Result:\nEpoch-013     8 Batches, Step    112, Testing Loss:  0.209404, Used Time:   0.1m, Remaining Time:   0.5m\n-------------------------------------------------------------------------------\nBest Metric: 0.20940438886078036\n####################################################################################\nEvaluate Result:\nEpoch-014     8 Batches, Step    120, Testing Loss:  0.208746, Used Time:   0.1m, Remaining Time:   0.5m\n-------------------------------------------------------------------------------\nBest Metric: 0.20874603548828435\n####################################################################################\nEvaluate Result:\nEpoch-015     8 Batches, Step    128, Testing Loss:  0.211754, Used Time:   0.1m, Remaining Time:   0.5m\n-------------------------------------------------------------------------------\nBest Metric: 0.20874603548828435\n####################################################################################\nEvaluate Result:\nEpoch-016     8 Batches, Step    136, Testing Loss:  0.202226, Used Time:   0.1m, Remaining Time:   0.5m\n-------------------------------------------------------------------------------\nBest Metric: 0.20222558263613252\n####################################################################################\nEvaluate Result:\nEpoch-017     8 Batches, Step    144, Testing Loss:  0.245433, Used Time:   0.1m, Remaining Time:   0.5m\n-------------------------------------------------------------------------------\nBest Metric: 0.20222558263613252\n####################################################################################\nEvaluate Result:\nEpoch-018     8 Batches, Step    152, Testing Loss:  0.190125, Used Time:   0.1m, Remaining Time:   0.5m\n-------------------------------------------------------------------------------\nBest Metric: 0.190124867826092\n####################################################################################\nEvaluate Result:\nEpoch-019     8 Batches, Step    160, Testing Loss:  0.194146, Used Time:   0.1m, Remaining Time:   0.5m\n-------------------------------------------------------------------------------\nBest Metric: 0.190124867826092\n####################################################################################\nEvaluate Result:\nEpoch-020     8 Batches, Step    168, Testing Loss:  0.199245, Used Time:   0.1m, Remaining Time:   0.5m\n-------------------------------------------------------------------------------\nBest Metric: 0.190124867826092\n####################################################################################\nEvaluate Result:\nEpoch-021     8 Batches, Step    176, Testing Loss:  0.193670, Used Time:   0.1m, Remaining Time:   0.5m\n-------------------------------------------------------------------------------\nBest Metric: 0.190124867826092\n####################################################################################\nEvaluate Result:\nEpoch-022     8 Batches, Step    184, Testing Loss:  0.174245, Used Time:   0.1m, Remaining Time:   0.5m\n-------------------------------------------------------------------------------\nBest Metric: 0.1742449053088013\n####################################################################################\nEvaluate Result:\nEpoch-023     8 Batches, Step    192, Testing Loss:  0.180811, Used Time:   0.2m, Remaining Time:   0.5m\n-------------------------------------------------------------------------------\nBest Metric: 0.1742449053088013\n####################################################################################\nEvaluate Result:\nEpoch-024     8 Batches, Step    200, Testing Loss:  0.169974, Used Time:   0.2m, Remaining Time:   0.5m\n-------------------------------------------------------------------------------\nBest Metric: 0.16997449981923007\n####################################################################################\nEvaluate Result:\nEpoch-025     8 Batches, Step    208, Testing Loss:  0.178219, Used Time:   0.2m, Remaining Time:   0.5m\n-------------------------------------------------------------------------------\nBest Metric: 0.16997449981923007\n####################################################################################\nEvaluate Result:\nEpoch-026     8 Batches, Step    216, Testing Loss:  0.282366, Used Time:   0.2m, Remaining Time:   0.5m\n-------------------------------------------------------------------------------\nBest Metric: 0.16997449981923007\n####################################################################################\nEvaluate Result:\nEpoch-027     8 Batches, Step    224, Testing Loss:  0.180953, Used Time:   0.2m, Remaining Time:   0.4m\n-------------------------------------------------------------------------------\nBest Metric: 0.16997449981923007\n####################################################################################\nEvaluate Result:\nEpoch-028     8 Batches, Step    232, Testing Loss:  0.190162, Used Time:   0.2m, Remaining Time:   0.4m\n-------------------------------------------------------------------------------\nBest Metric: 0.16997449981923007\n####################################################################################\nEvaluate Result:\nEpoch-029     8 Batches, Step    240, Testing Loss:  0.196574, Used Time:   0.2m, Remaining Time:   0.4m\n-------------------------------------------------------------------------------\nBest Metric: 0.16997449981923007\n####################################################################################\nEvaluate Result:\nEpoch-030     8 Batches, Step    248, Testing Loss:  0.194053, Used Time:   0.2m, Remaining Time:   0.4m\n-------------------------------------------------------------------------------\nBest Metric: 0.16997449981923007\n####################################################################################\nEvaluate Result:\nEpoch-031     8 Batches, Step    256, Testing Loss:  0.233555, Used Time:   0.2m, Remaining Time:   0.4m\n-------------------------------------------------------------------------------\nBest Metric: 0.16997449981923007\n####################################################################################\nEvaluate Result:\nEpoch-032     8 Batches, Step    264, Testing Loss:  0.222633, Used Time:   0.2m, Remaining Time:   0.4m\n-------------------------------------------------------------------------------\nBest Metric: 0.16997449981923007\n####################################################################################\nEvaluate Result:\nEpoch-033     8 Batches, Step    272, Testing Loss:  0.187330, Used Time:   0.2m, Remaining Time:   0.4m\n-------------------------------------------------------------------------------\nBest Metric: 0.16997449981923007\n####################################################################################\nEvaluate Result:\nEpoch-034     8 Batches, Step    280, Testing Loss:  0.194431, Used Time:   0.2m, Remaining Time:   0.4m\n-------------------------------------------------------------------------------\nBest Metric: 0.16997449981923007\n####################################################################################\nEvaluate Result:\nEpoch-035     8 Batches, Step    288, Testing Loss:  0.268355, Used Time:   0.2m, Remaining Time:   0.4m\n-------------------------------------------------------------------------------\nBest Metric: 0.16997449981923007\n####################################################################################\nEvaluate Result:\nEpoch-036     8 Batches, Step    296, Testing Loss:  0.171511, Used Time:   0.2m, Remaining Time:   0.4m\n-------------------------------------------------------------------------------\nBest Metric: 0.16997449981923007\n####################################################################################\nEvaluate Result:\nEpoch-037     4 Batches, Step    300, Testing Loss:  0.163444, Used Time:   0.2m, Remaining Time:   0.4m\n-------------------------------------------------------------------------------\nEvaluate Result:\nEpoch-037     8 Batches, Step    304, Testing Loss:  0.182596, Used Time:   0.2m, Remaining Time:   0.4m\n-------------------------------------------------------------------------------\nBest Metric: 0.1634439071830438\n####################################################################################\nEvaluate Result:\nEpoch-038     8 Batches, Step    312, Testing Loss:  0.170622, Used Time:   0.2m, Remaining Time:   0.4m\n-------------------------------------------------------------------------------\nBest Metric: 0.1634439071830438\n####################################################################################\nEvaluate Result:\nEpoch-039     8 Batches, Step    320, Testing Loss:  0.155859, Used Time:   0.2m, Remaining Time:   0.4m\n-------------------------------------------------------------------------------\nBest Metric: 0.15585906225807813\n####################################################################################\nEvaluate Result:\nEpoch-040     8 Batches, Step    328, Testing Loss:  0.175854, Used Time:   0.3m, Remaining Time:   0.4m\n-------------------------------------------------------------------------------\nBest Metric: 0.15585906225807813\n####################################################################################\nEvaluate Result:\nEpoch-041     8 Batches, Step    336, Testing Loss:  0.185298, Used Time:   0.3m, Remaining Time:   0.4m\n-------------------------------------------------------------------------------\nBest Metric: 0.15585906225807813\n####################################################################################\nEvaluate Result:\nEpoch-042     8 Batches, Step    344, Testing Loss:  0.163275, Used Time:   0.3m, Remaining Time:   0.4m\n-------------------------------------------------------------------------------\nBest Metric: 0.15585906225807813\n####################################################################################\nEvaluate Result:\nEpoch-043     8 Batches, Step    352, Testing Loss:  0.174582, Used Time:   0.3m, Remaining Time:   0.3m\n-------------------------------------------------------------------------------\nBest Metric: 0.15585906225807813\n####################################################################################\nEvaluate Result:\nEpoch-044     8 Batches, Step    360, Testing Loss:  0.171353, Used Time:   0.3m, Remaining Time:   0.3m\n-------------------------------------------------------------------------------\nBest Metric: 0.15585906225807813\n####################################################################################\nEvaluate Result:\nEpoch-045     8 Batches, Step    368, Testing Loss:  0.196150, Used Time:   0.3m, Remaining Time:   0.3m\n-------------------------------------------------------------------------------\nBest Metric: 0.15585906225807813\n####################################################################################\nEvaluate Result:\nEpoch-046     8 Batches, Step    376, Testing Loss:  0.159812, Used Time:   0.3m, Remaining Time:   0.3m\n-------------------------------------------------------------------------------\nBest Metric: 0.15585906225807813\n####################################################################################\nEvaluate Result:\nEpoch-047     8 Batches, Step    384, Testing Loss:  0.172659, Used Time:   0.3m, Remaining Time:   0.3m\n-------------------------------------------------------------------------------\nBest Metric: 0.15585906225807813\n####################################################################################\nEvaluate Result:\nEpoch-048     8 Batches, Step    392, Testing Loss:  0.204180, Used Time:   0.3m, Remaining Time:   0.3m\n-------------------------------------------------------------------------------\nBest Metric: 0.15585906225807813\n####################################################################################\nEvaluate Result:\nEpoch-049     8 Batches, Step    400, Testing Loss:  0.177394, Used Time:   0.3m, Remaining Time:   0.3m\n-------------------------------------------------------------------------------\nBest Metric: 0.15585906225807813\n####################################################################################\nEvaluate Result:\nEpoch-050     8 Batches, Step    408, Testing Loss:  0.209053, Used Time:   0.3m, Remaining Time:   0.3m\n-------------------------------------------------------------------------------\nBest Metric: 0.15585906225807813\n####################################################################################\nEvaluate Result:\nEpoch-051     8 Batches, Step    416, Testing Loss:  0.215112, Used Time:   0.3m, Remaining Time:   0.3m\n-------------------------------------------------------------------------------\nBest Metric: 0.15585906225807813\n####################################################################################\nEvaluate Result:\nEpoch-052     8 Batches, Step    424, Testing Loss:  0.203654, Used Time:   0.3m, Remaining Time:   0.3m\n-------------------------------------------------------------------------------\nBest Metric: 0.15585906225807813\n####################################################################################\nEvaluate Result:\nEpoch-053     8 Batches, Step    432, Testing Loss:  0.179458, Used Time:   0.3m, Remaining Time:   0.3m\n-------------------------------------------------------------------------------\nBest Metric: 0.15585906225807813\n####################################################################################\nEvaluate Result:\nEpoch-054     8 Batches, Step    440, Testing Loss:  0.205180, Used Time:   0.3m, Remaining Time:   0.3m\n-------------------------------------------------------------------------------\nBest Metric: 0.15585906225807813\n####################################################################################\nEvaluate Result:\nEpoch-055     8 Batches, Step    448, Testing Loss:  0.201024, Used Time:   0.3m, Remaining Time:   0.3m\n-------------------------------------------------------------------------------\nBest Metric: 0.15585906225807813\n####################################################################################\nEvaluate Result:\nEpoch-056     8 Batches, Step    456, Testing Loss:  0.228876, Used Time:   0.4m, Remaining Time:   0.3m\n-------------------------------------------------------------------------------\nBest Metric: 0.15585906225807813\n####################################################################################\nEvaluate Result:\nEpoch-057     8 Batches, Step    464, Testing Loss:  0.195855, Used Time:   0.4m, Remaining Time:   0.3m\n-------------------------------------------------------------------------------\nBest Metric: 0.15585906225807813\n####################################################################################\nEvaluate Result:\nEpoch-058     8 Batches, Step    472, Testing Loss:  0.177376, Used Time:   0.4m, Remaining Time:   0.3m\n-------------------------------------------------------------------------------\nBest Metric: 0.15585906225807813\n####################################################################################\nEvaluate Result:\nEpoch-059     8 Batches, Step    480, Testing Loss:  0.172209, Used Time:   0.4m, Remaining Time:   0.2m\n-------------------------------------------------------------------------------\nBest Metric: 0.15585906225807813\n####################################################################################\nEvaluate Result:\nEpoch-060     8 Batches, Step    488, Testing Loss:  0.186898, Used Time:   0.4m, Remaining Time:   0.2m\n-------------------------------------------------------------------------------\nBest Metric: 0.15585906225807813\n####################################################################################\nEvaluate Result:\nEpoch-061     8 Batches, Step    496, Testing Loss:  0.183682, Used Time:   0.4m, Remaining Time:   0.2m\n-------------------------------------------------------------------------------\nBest Metric: 0.15585906225807813\n####################################################################################\nEpoch-062     4 Batches, Step    500, Training Loss:  0.084723 (AllAvg  0.084723)\nEvaluate Result:\nEpoch-062     8 Batches, Step    504, Testing Loss:  0.180159, Used Time:   0.4m, Remaining Time:   0.2m\n-------------------------------------------------------------------------------\nBest Metric: 0.15585906225807813\n####################################################################################\nEvaluate Result:\nEpoch-063     8 Batches, Step    512, Testing Loss:  0.201366, Used Time:   0.4m, Remaining Time:   0.2m\n-------------------------------------------------------------------------------\nBest Metric: 0.15585906225807813\n####################################################################################\nEvaluate Result:\nEpoch-064     8 Batches, Step    520, Testing Loss:  0.249911, Used Time:   0.4m, Remaining Time:   0.2m\n-------------------------------------------------------------------------------\nBest Metric: 0.15585906225807813\n####################################################################################\nEvaluate Result:\nEpoch-065     8 Batches, Step    528, Testing Loss:  0.204929, Used Time:   0.4m, Remaining Time:   0.2m\n-------------------------------------------------------------------------------\nBest Metric: 0.15585906225807813\n####################################################################################\nEvaluate Result:\nEpoch-066     8 Batches, Step    536, Testing Loss:  0.188268, Used Time:   0.4m, Remaining Time:   0.2m\n-------------------------------------------------------------------------------\nBest Metric: 0.15585906225807813\n####################################################################################\nEvaluate Result:\nEpoch-067     8 Batches, Step    544, Testing Loss:  0.225718, Used Time:   0.4m, Remaining Time:   0.2m\n-------------------------------------------------------------------------------\nBest Metric: 0.15585906225807813\n####################################################################################\nEvaluate Result:\nEpoch-068     8 Batches, Step    552, Testing Loss:  0.197825, Used Time:   0.4m, Remaining Time:   0.2m\n-------------------------------------------------------------------------------\nBest Metric: 0.15585906225807813\n####################################################################################\nEvaluate Result:\nEpoch-069     8 Batches, Step    560, Testing Loss:  0.198515, Used Time:   0.4m, Remaining Time:   0.2m\n-------------------------------------------------------------------------------\nBest Metric: 0.15585906225807813\n####################################################################################\nEvaluate Result:\nEpoch-070     8 Batches, Step    568, Testing Loss:  0.197811, Used Time:   0.4m, Remaining Time:   0.2m\n-------------------------------------------------------------------------------\nBest Metric: 0.15585906225807813\n####################################################################################\nEvaluate Result:\nEpoch-071     8 Batches, Step    576, Testing Loss:  0.201396, Used Time:   0.4m, Remaining Time:   0.2m\n-------------------------------------------------------------------------------\nBest Metric: 0.15585906225807813\n####################################################################################\nEvaluate Result:\nEpoch-072     8 Batches, Step    584, Testing Loss:  0.227485, Used Time:   0.4m, Remaining Time:   0.2m\n-------------------------------------------------------------------------------\nBest Metric: 0.15585906225807813\n####################################################################################\nEvaluate Result:\nEpoch-073     8 Batches, Step    592, Testing Loss:  0.189716, Used Time:   0.5m, Remaining Time:   0.2m\n-------------------------------------------------------------------------------\nBest Metric: 0.15585906225807813\n####################################################################################\nEvaluate Result:\nEpoch-074     8 Batches, Step    600, Testing Loss:  0.175786, Used Time:   0.5m, Remaining Time:   0.2m\n-------------------------------------------------------------------------------\nBest Metric: 0.15585906225807813\n####################################################################################\nEvaluate Result:\nEpoch-075     8 Batches, Step    608, Testing Loss:  0.205583, Used Time:   0.5m, Remaining Time:   0.1m\n-------------------------------------------------------------------------------\nBest Metric: 0.15585906225807813\n####################################################################################\nEvaluate Result:\nEpoch-076     8 Batches, Step    616, Testing Loss:  0.200993, Used Time:   0.5m, Remaining Time:   0.1m\n-------------------------------------------------------------------------------\nBest Metric: 0.15585906225807813\n####################################################################################\nEvaluate Result:\nEpoch-077     8 Batches, Step    624, Testing Loss:  0.203586, Used Time:   0.5m, Remaining Time:   0.1m\n-------------------------------------------------------------------------------\nBest Metric: 0.15585906225807813\n####################################################################################\nEvaluate Result:\nEpoch-078     8 Batches, Step    632, Testing Loss:  0.221537, Used Time:   0.5m, Remaining Time:   0.1m\n-------------------------------------------------------------------------------\nBest Metric: 0.15585906225807813\n####################################################################################\nEvaluate Result:\nEpoch-079     8 Batches, Step    640, Testing Loss:  0.194540, Used Time:   0.5m, Remaining Time:   0.1m\n-------------------------------------------------------------------------------\nBest Metric: 0.15585906225807813\n####################################################################################\nEvaluate Result:\nEpoch-080     8 Batches, Step    648, Testing Loss:  0.214367, Used Time:   0.5m, Remaining Time:   0.1m\n-------------------------------------------------------------------------------\nBest Metric: 0.15585906225807813\n####################################################################################\nEvaluate Result:\nEpoch-081     8 Batches, Step    656, Testing Loss:  0.202480, Used Time:   0.5m, Remaining Time:   0.1m\n-------------------------------------------------------------------------------\nBest Metric: 0.15585906225807813\n####################################################################################\nEvaluate Result:\nEpoch-082     8 Batches, Step    664, Testing Loss:  0.194256, Used Time:   0.5m, Remaining Time:   0.1m\n-------------------------------------------------------------------------------\nBest Metric: 0.15585906225807813\n####################################################################################\nEvaluate Result:\nEpoch-083     8 Batches, Step    672, Testing Loss:  0.197589, Used Time:   0.5m, Remaining Time:   0.1m\n-------------------------------------------------------------------------------\nBest Metric: 0.15585906225807813\n####################################################################################\nEvaluate Result:\nEpoch-084     8 Batches, Step    680, Testing Loss:  0.216802, Used Time:   0.5m, Remaining Time:   0.1m\n-------------------------------------------------------------------------------\nBest Metric: 0.15585906225807813\n####################################################################################\nEvaluate Result:\nEpoch-085     8 Batches, Step    688, Testing Loss:  0.211118, Used Time:   0.5m, Remaining Time:   0.1m\n-------------------------------------------------------------------------------\nBest Metric: 0.15585906225807813\n####################################################################################\nEvaluate Result:\nEpoch-086     8 Batches, Step    696, Testing Loss:  0.190461, Used Time:   0.5m, Remaining Time:   0.1m\n-------------------------------------------------------------------------------\nBest Metric: 0.15585906225807813\n####################################################################################\nEvaluate Result:\nEpoch-087     8 Batches, Step    704, Testing Loss:  0.221563, Used Time:   0.5m, Remaining Time:   0.1m\n-------------------------------------------------------------------------------\nBest Metric: 0.15585906225807813\n####################################################################################\nEvaluate Result:\nEpoch-088     8 Batches, Step    712, Testing Loss:  0.210590, Used Time:   0.5m, Remaining Time:   0.1m\n-------------------------------------------------------------------------------\nBest Metric: 0.15585906225807813\n####################################################################################\nEvaluate Result:\nEpoch-089     8 Batches, Step    720, Testing Loss:  0.198387, Used Time:   0.6m, Remaining Time:   0.1m\n-------------------------------------------------------------------------------\nBest Metric: 0.15585906225807813\n####################################################################################\nEvaluate Result:\nEpoch-090     8 Batches, Step    728, Testing Loss:  0.184746, Used Time:   0.6m, Remaining Time:   0.1m\n-------------------------------------------------------------------------------\nBest Metric: 0.15585906225807813\n####################################################################################\nEvaluate Result:\nEpoch-091     8 Batches, Step    736, Testing Loss:  0.201809, Used Time:   0.6m, Remaining Time:   0.0m\n-------------------------------------------------------------------------------\nBest Metric: 0.15585906225807813\n####################################################################################\nEvaluate Result:\nEpoch-092     8 Batches, Step    744, Testing Loss:  0.194560, Used Time:   0.6m, Remaining Time:   0.0m\n-------------------------------------------------------------------------------\nBest Metric: 0.15585906225807813\n####################################################################################\nEvaluate Result:\nEpoch-093     8 Batches, Step    752, Testing Loss:  0.184408, Used Time:   0.6m, Remaining Time:   0.0m\n-------------------------------------------------------------------------------\nBest Metric: 0.15585906225807813\n####################################################################################\nEvaluate Result:\nEpoch-094     8 Batches, Step    760, Testing Loss:  0.197393, Used Time:   0.6m, Remaining Time:   0.0m\n-------------------------------------------------------------------------------\nBest Metric: 0.15585906225807813\n####################################################################################\nEvaluate Result:\nEpoch-095     8 Batches, Step    768, Testing Loss:  0.243157, Used Time:   0.6m, Remaining Time:   0.0m\n-------------------------------------------------------------------------------\nBest Metric: 0.15585906225807813\n####################################################################################\nEvaluate Result:\nEpoch-096     8 Batches, Step    776, Testing Loss:  0.190552, Used Time:   0.6m, Remaining Time:   0.0m\n-------------------------------------------------------------------------------\nBest Metric: 0.15585906225807813\n####################################################################################\nEvaluate Result:\nEpoch-097     8 Batches, Step    784, Testing Loss:  0.208064, Used Time:   0.6m, Remaining Time:   0.0m\n-------------------------------------------------------------------------------\nBest Metric: 0.15585906225807813\n####################################################################################\nEvaluate Result:\nEpoch-098     8 Batches, Step    792, Testing Loss:  0.189216, Used Time:   0.6m, Remaining Time:   0.0m\n-------------------------------------------------------------------------------\nBest Metric: 0.15585906225807813\n####################################################################################\nEvaluate Result:\nEpoch-099     8 Batches, Step    800, Testing Loss:  0.184819, Used Time:   0.6m, Remaining Time:   0.0m\n-------------------------------------------------------------------------------\nBest Metric: 0.15585906225807813\n####################################################################################\nFinal Best Metric: 0.15585906225807813\nFinal metrics: 0.18481869\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=de072003-a9db-4342-8067-19a4b45feff1' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>",
   "metadata": {
    "tags": [],
    "created_in_deepnote_cell": true,
    "deepnote_cell_type": "markdown"
   }
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "orig_nbformat": 2,
  "deepnote": {
   "is_reactive": false
  },
  "deepnote_notebook_id": "9c56fb53-f558-4ba7-af3c-26057205192b",
  "deepnote_execution_queue": []
 }
}