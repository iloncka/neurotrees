{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rMs0rw-frIOZ"
   },
   "source": [
    "## Installations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V58UCIkhbr-5"
   },
   "source": [
    "# DeepGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bkfqngXoet5q"
   },
   "source": [
    "Guolin Ke, Zhenhui Xu, Jia Zhang, Jiang Bian, and Tie-yan Liu. \"DeepGBM: A Deep Learning Framework Distilled  by GBDT for Online Prediction Tasks.\" In Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining, ACM, 2019.  \n",
    "\n",
    "[Article](https://dl.acm.org/doi/10.1145/3292500.3330858)  \n",
    "\n",
    "[GitHub](https://github.com/motefly/DeepGBM)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "taz_w_xddpph"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# pd.set_option('display.max_columns', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "GARfc0WQh5Hr"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import category_encoders as ce\n",
    "from tqdm import tqdm\n",
    "import collections, os\n",
    "import gc\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NIc6EJFarbGS"
   },
   "source": [
    "Here code for preprocessing from paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cellView": "form",
    "id": "DqRhmpeEiUIZ"
   },
   "outputs": [],
   "source": [
    "#@title\n",
    "def unpackbits(x,num_bits):\n",
    "    xshape = list(x.shape)\n",
    "    x = x.reshape([-1,1])\n",
    "    to_and = 2**np.arange(num_bits).reshape([1,num_bits])\n",
    "    return (x & to_and).astype(bool).astype(int).reshape(xshape + [num_bits])\n",
    "\n",
    "class NumEncoder(object):\n",
    "    def __init__(self, cate_col, nume_col, threshold, thresrate, label):\n",
    "        self.label_name = label\n",
    "        # cate_col = list(df.select_dtypes(include=['object']))\n",
    "        self.cate_col = cate_col\n",
    "        # nume_col = list(set(list(df)) - set(cate_col))\n",
    "        self.dtype_dict = {}\n",
    "        for item in cate_col:\n",
    "            self.dtype_dict[item] = 'str'\n",
    "        for item in nume_col:\n",
    "            self.dtype_dict[item] = 'float'\n",
    "        self.nume_col = nume_col\n",
    "        self.tgt_nume_col = []\n",
    "        self.encoder = ce.ordinal.OrdinalEncoder(cols=cate_col)\n",
    "        self.threshold = threshold\n",
    "        self.thresrate = thresrate\n",
    "        # for online update, to do\n",
    "        self.save_cate_avgs = {}\n",
    "        self.save_value_filter = {}\n",
    "        self.save_num_embs = {}\n",
    "        self.Max_len = {}\n",
    "        self.samples = 0\n",
    "\n",
    "    def fit_transform(self, inPath, outPath):\n",
    "        print('----------------------------------------------------------------------')\n",
    "        print('Fitting and Transforming %s .'%inPath)\n",
    "        print('----------------------------------------------------------------------')\n",
    "        df = pd.read_csv(inPath, dtype=self.dtype_dict)\n",
    "        self.samples = df.shape[0]\n",
    "        print('Filtering and fillna features')\n",
    "        for item in tqdm(self.cate_col):\n",
    "            value_counts = df[item].value_counts()\n",
    "            num = value_counts.shape[0]\n",
    "            self.save_value_filter[item] = list(value_counts[:int(num*self.thresrate)][value_counts>self.threshold].index)\n",
    "            rm_values = set(value_counts.index)-set(self.save_value_filter[item])\n",
    "            df[item] = df[item].map(lambda x: '<LESS>' if x in rm_values else x)\n",
    "            df[item] = df[item].fillna('<UNK>')\n",
    "            del value_counts\n",
    "            gc.collect()\n",
    "\n",
    "        for item in tqdm(self.nume_col):\n",
    "            df[item] = df[item].fillna(df[item].mean())\n",
    "            self.save_num_embs[item] = {'sum':df[item].sum(), 'cnt':df[item].shape[0]}\n",
    "\n",
    "        print('Ordinal encoding cate features')\n",
    "        # ordinal_encoding\n",
    "        df = self.encoder.fit_transform(df)\n",
    "\n",
    "        print('Target encoding cate features')\n",
    "        # dynamic_targeting_encoding\n",
    "        for item in tqdm(self.cate_col):\n",
    "            feats = df[item].values\n",
    "            labels = df[self.label_name].values\n",
    "            feat_encoding = {'mean':[], 'count':[]}\n",
    "            feat_temp_result = collections.defaultdict(lambda : [0, 0])\n",
    "            self.save_cate_avgs[item] = collections.defaultdict(lambda : [0, 0])\n",
    "            for idx in range(self.samples):\n",
    "                cur_feat = feats[idx]\n",
    "                # smoothing optional\n",
    "                if cur_feat in self.save_cate_avgs[item]:\n",
    "                    # feat_temp_result[cur_feat][0] = 0.9*feat_temp_result[cur_feat][0] + 0.1*self.save_cate_avgs[item][cur_feat][0]/self.save_cate_avgs[item][cur_feat][1]\n",
    "                    # feat_temp_result[cur_feat][1] = 0.9*feat_temp_result[cur_feat][1] + 0.1*self.save_cate_avgs[item][cur_feat][1]/idx\n",
    "                    feat_encoding['mean'].append(self.save_cate_avgs[item][cur_feat][0]/self.save_cate_avgs[item][cur_feat][1])\n",
    "                    feat_encoding['count'].append(self.save_cate_avgs[item][cur_feat][1]/idx)\n",
    "                else:\n",
    "                    feat_encoding['mean'].append(0)\n",
    "                    feat_encoding['count'].append(0)\n",
    "                self.save_cate_avgs[item][cur_feat][0] += labels[idx]\n",
    "                self.save_cate_avgs[item][cur_feat][1] += 1\n",
    "            df[item+'_t_mean'] = feat_encoding['mean']\n",
    "            df[item+'_t_count'] = feat_encoding['count']\n",
    "            self.tgt_nume_col.append(item+'_t_mean')\n",
    "            self.tgt_nume_col.append(item+'_t_count')\n",
    "        \n",
    "        print('Start manual binary encode')\n",
    "        rows = None\n",
    "        for item in tqdm(self.nume_col+self.tgt_nume_col):\n",
    "            feats = df[item].values\n",
    "            if rows is None:\n",
    "                rows = feats.reshape((-1,1))\n",
    "            else:\n",
    "                rows = np.concatenate([rows,feats.reshape((-1,1))],axis=1)\n",
    "            del feats\n",
    "            gc.collect()\n",
    "        for item in tqdm(self.cate_col):\n",
    "            feats = df[item].values\n",
    "            Max = df[item].max()\n",
    "            bit_len = len(bin(Max)) - 2\n",
    "            samples = self.samples\n",
    "            self.Max_len[item] = bit_len\n",
    "            res = unpackbits(feats, bit_len).reshape((samples,-1))\n",
    "            rows = np.concatenate([rows,res],axis=1)\n",
    "            del feats\n",
    "            gc.collect()\n",
    "        trn_y = np.array(df[self.label_name].values).reshape((-1,1))\n",
    "        del df\n",
    "        gc.collect()\n",
    "        trn_x = np.array(rows)\n",
    "        np.save(outPath+'_features.npy', trn_x)\n",
    "        np.save(outPath+'_labels.npy', trn_y)\n",
    "\n",
    "    # for test dataset\n",
    "    def transform(self, inPath, outPath):\n",
    "        print('----------------------------------------------------------------------')\n",
    "        print('Transforming %s .'%inPath)\n",
    "        print('----------------------------------------------------------------------')\n",
    "        df = pd.read_csv(inPath, dtype=self.dtype_dict)\n",
    "        samples = df.shape[0]\n",
    "        print('Filtering and fillna features')\n",
    "        for item in tqdm(self.cate_col):\n",
    "            value_counts = df[item].value_counts()\n",
    "            rm_values = set(value_counts.index)-set(self.save_value_filter[item])\n",
    "            df[item] = df[item].map(lambda x: '<LESS>' if x in rm_values else x)\n",
    "            df[item] = df[item].fillna('<UNK>')\n",
    "\n",
    "        for item in tqdm(self.nume_col):\n",
    "            mean = self.save_num_embs[item]['sum'] / self.save_num_embs[item]['cnt']\n",
    "            df[item] = df[item].fillna(mean)\n",
    "\n",
    "        print('Ordinal encoding cate features')\n",
    "        # ordinal_encoding\n",
    "        df = self.encoder.transform(df)\n",
    "\n",
    "        print('Target encoding cate features')\n",
    "        # dynamic_targeting_encoding\n",
    "        for item in tqdm(self.cate_col):\n",
    "            avgs = self.save_cate_avgs[item]\n",
    "            df[item+'_t_mean'] = df[item].map(lambda x: avgs[x][0]/avgs[x][1] if x in avgs else 0)\n",
    "            df[item+'_t_count'] = df[item].map(lambda x: avgs[x][1]/self.samples if x in avgs else 0)\n",
    "        \n",
    "        print('Start manual binary encode')\n",
    "        rows = None\n",
    "        for item in tqdm(self.nume_col+self.tgt_nume_col):\n",
    "            feats = df[item].values\n",
    "            if rows is None:\n",
    "                rows = feats.reshape((-1,1))\n",
    "            else:\n",
    "                rows = np.concatenate([rows,feats.reshape((-1,1))],axis=1)\n",
    "            del feats\n",
    "            gc.collect()\n",
    "        for item in tqdm(self.cate_col):\n",
    "            feats = df[item].values\n",
    "            bit_len = self.Max_len[item]\n",
    "            res = unpackbits(feats, bit_len).reshape((samples,-1))\n",
    "            rows = np.concatenate([rows,res],axis=1)\n",
    "            del feats\n",
    "            gc.collect()\n",
    "        vld_y = np.array(df[self.label_name].values).reshape((-1,1))\n",
    "        del df\n",
    "        gc.collect()\n",
    "        vld_x = np.array(rows)\n",
    "        np.save(outPath+'_features.npy', vld_x)\n",
    "        np.save(outPath+'_labels.npy', vld_y)\n",
    "    \n",
    "    # for update online dataset\n",
    "    def refit_transform(self, inPath, outPath):\n",
    "        print('----------------------------------------------------------------------')\n",
    "        print('Refitting and Transforming %s .'%inPath)\n",
    "        print('----------------------------------------------------------------------')\n",
    "        df = pd.read_csv(inPath, dtype=self.dtype_dict)\n",
    "        samples = df.shape[0]\n",
    "        print('Filtering and fillna features')\n",
    "        for item in tqdm(self.cate_col):\n",
    "            value_counts = df[item].value_counts()\n",
    "            rm_values = set(value_counts.index)-set(self.save_value_filter[item])\n",
    "            df[item] = df[item].map(lambda x: '<LESS>' if x in rm_values else x)\n",
    "            df[item] = df[item].fillna('<UNK>')\n",
    "\n",
    "        for item in tqdm(self.nume_col):\n",
    "            self.save_num_embs[item]['sum'] += df[item].sum()\n",
    "            self.save_num_embs[item]['cnt'] += df[item].shape[0]\n",
    "            mean = self.save_num_embs[item]['sum'] / self.save_num_embs[item]['cnt']\n",
    "            df[item] = df[item].fillna(mean)\n",
    "\n",
    "        print('Ordinal encoding cate features')\n",
    "        # ordinal_encoding\n",
    "        df = self.encoder.transform(df)\n",
    "\n",
    "        print('Target encoding cate features')\n",
    "        # dynamic_targeting_encoding\n",
    "        for item in tqdm(self.cate_col):\n",
    "            feats = df[item].values\n",
    "            labels = df[self.label_name].values\n",
    "            feat_encoding = {'mean':[], 'count':[]}\n",
    "            for idx in range(samples):\n",
    "                cur_feat = feats[idx]\n",
    "                if self.save_cate_avgs[item][cur_feat][1] == 0:\n",
    "                    pdb.set_trace()\n",
    "                feat_encoding['mean'].append(self.save_cate_avgs[item][cur_feat][0]/self.save_cate_avgs[item][cur_feat][1])\n",
    "                feat_encoding['count'].append(self.save_cate_avgs[item][cur_feat][1]/(self.samples+idx))\n",
    "                self.save_cate_avgs[item][cur_feat][0] += labels[idx]\n",
    "                self.save_cate_avgs[item][cur_feat][1] += 1\n",
    "            df[item+'_t_mean'] = feat_encoding['mean']\n",
    "            df[item+'_t_count'] = feat_encoding['count']\n",
    "\n",
    "        self.samples += samples\n",
    "            \n",
    "        print('Start manual binary encode')\n",
    "        rows = None\n",
    "        for item in tqdm(self.nume_col+self.tgt_nume_col):\n",
    "            feats = df[item].values\n",
    "            if rows is None:\n",
    "                rows = feats.reshape((-1,1))\n",
    "            else:\n",
    "                rows = np.concatenate([rows,feats.reshape((-1,1))],axis=1)\n",
    "            del feats\n",
    "            gc.collect()\n",
    "        for item in tqdm(self.cate_col):\n",
    "            feats = df[item].values\n",
    "            bit_len = self.Max_len[item]\n",
    "            res = unpackbits(feats, bit_len).reshape((samples,-1))\n",
    "            rows = np.concatenate([rows,res],axis=1)\n",
    "            del feats\n",
    "            gc.collect()\n",
    "        vld_y = np.array(df[self.label_name].values).reshape((-1,1))\n",
    "        del df\n",
    "        gc.collect()\n",
    "        vld_x = np.array(rows)\n",
    "        np.save(outPath+'_features.npy', vld_x)\n",
    "        np.save(outPath+'_labels.npy', vld_y)\n",
    "        # to do\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cellView": "form",
    "id": "O14Rf43Tru5b"
   },
   "outputs": [],
   "source": [
    "#@title\n",
    "class CateEncoder(object):\n",
    "    def __init__(self, cate_col, nume_col, threshold, thresrate, bins, label):\n",
    "        self.label_name = label\n",
    "        # cate_col = list(df.select_dtypes(include=['object']))\n",
    "        self.cate_col = cate_col \n",
    "        # nume_col = list(set(list(df)) - set(cate_col))\n",
    "        self.dtype_dict = {}\n",
    "        for item in cate_col:\n",
    "            self.dtype_dict[item] = 'str'\n",
    "        for item in nume_col:\n",
    "            self.dtype_dict[item] = 'float'\n",
    "        self.nume_col = nume_col\n",
    "        self.encoder = ce.ordinal.OrdinalEncoder(cols=cate_col+nume_col)\n",
    "        self.threshold = threshold\n",
    "        self.thresrate = thresrate\n",
    "        self.bins = bins\n",
    "        # for online update, to do\n",
    "        self.save_value_filter = {}\n",
    "        self.save_num_bins = {}\n",
    "        self.samples = 0\n",
    "\n",
    "    def save2npy(self, df, out_dir):\n",
    "        if not os.path.isdir(out_dir):\n",
    "            os.mkdir(out_dir)\n",
    "        result = {'label':[], 'index':[],'feature_sizes':[]}\n",
    "        result['label'] = df[self.label_name].values\n",
    "        result['index'] = df[self.cate_col+self.nume_col].values\n",
    "        for item in self.cate_col+self.nume_col:\n",
    "            result['feature_sizes'].append(df[item].max()+1)\n",
    "        for item in result:\n",
    "            result[item] = np.array(result[item])\n",
    "            np.save(out_dir + '_' + item +'.npy', result[item])\n",
    "\n",
    "    def fit_transform(self, inPath, outPath):\n",
    "        print('----------------------------------------------------------------------')\n",
    "        print('Fitting and Transforming %s .'%inPath)\n",
    "        print('----------------------------------------------------------------------')\n",
    "        df = pd.read_csv(inPath, dtype=self.dtype_dict)\n",
    "        print('Filtering and fillna features')\n",
    "        for item in tqdm(self.cate_col):\n",
    "            value_counts = df[item].value_counts()\n",
    "            num = value_counts.shape[0]\n",
    "            self.save_value_filter[item] = list(value_counts[:int(num*self.thresrate)][value_counts>self.threshold].index)\n",
    "            rm_values = set(value_counts.index)-set(self.save_value_filter[item])\n",
    "            df[item] = df[item].map(lambda x: '<LESS>' if x in rm_values else x)\n",
    "            df[item] = df[item].fillna('<UNK>')\n",
    "\n",
    "        print('Fillna and Bucketize numeric features')\n",
    "        for item in tqdm(self.nume_col):\n",
    "            q_res = pd.qcut(df[item], self.bins, labels=False, retbins=True, duplicates='drop')\n",
    "            df[item] = q_res[0].fillna(-1).astype('int')\n",
    "            self.save_num_bins[item] = q_res[1]\n",
    "\n",
    "        print('Ordinal encoding cate features')\n",
    "        # ordinal_encoding\n",
    "        df = self.encoder.fit_transform(df)\n",
    "        self.save2npy(df, outPath)\n",
    "        # df.to_csv(outPath, index=False)\n",
    "\n",
    "    # for test dataset\n",
    "    def transform(self, inPath, outPath):\n",
    "        print('----------------------------------------------------------------------')\n",
    "        print('Transforming %s .'%inPath)\n",
    "        print('----------------------------------------------------------------------')\n",
    "        df = pd.read_csv(inPath, dtype=self.dtype_dict)\n",
    "        print('Filtering and fillna features')\n",
    "        for item in tqdm(self.cate_col):\n",
    "            value_counts = df[item].value_counts()\n",
    "            rm_values = set(value_counts.index)-set(self.save_value_filter[item])\n",
    "            df[item] = df[item].map(lambda x: '<LESS>' if x in rm_values else x)\n",
    "            df[item] = df[item].fillna('<UNK>')\n",
    "\n",
    "        for item in tqdm(self.nume_col):\n",
    "            df[item] = pd.cut(df[item], self.save_num_bins[item], labels=False, include_lowest=True).fillna(-1).astype('int')\n",
    "\n",
    "        print('Ordinal encoding cate features')\n",
    "        # ordinal_encoding\n",
    "        df = self.encoder.transform(df)\n",
    "        self.save2npy(df, outPath)\n",
    "        # df.to_csv(outPath, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aVMUBvOyGY7F"
   },
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 211
    },
    "id": "tDkAgyKobw_G",
    "outputId": "036d5ce8-8e9b-4ad5-91a7-199b70637fcc"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.36</td>\n",
       "      <td>20.7</td>\n",
       "      <td>0.045</td>\n",
       "      <td>45.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>1.001</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.45</td>\n",
       "      <td>8.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.049</td>\n",
       "      <td>14.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.994</td>\n",
       "      <td>3.3</td>\n",
       "      <td>0.49</td>\n",
       "      <td>9.5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.0              0.27         0.36            20.7      0.045   \n",
       "1            6.3              0.30         0.34             1.6      0.049   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density   pH  sulphates  \\\n",
       "0                 45.0                 170.0    1.001  3.0       0.45   \n",
       "1                 14.0                 132.0    0.994  3.3       0.49   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      8.8        6  \n",
       "1      9.5        6  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# file_url = \"http://storage.googleapis.com/download.tensorflow.org/data/heart.csv\"\n",
    "# file_url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/ionosphere/ionosphere.data\"\n",
    "file_url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv\"\n",
    "# file_url = \"https://storage.yandexcloud.net/datasouls-ods/materials/3b9757b5/train_data.csv\"\n",
    "# file_url = \"https://download.mlcc.google.com/mledu-datasets/california_housing_train.csv\"\n",
    "df = pd.read_csv(file_url, sep=';')\n",
    "\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Kw0eIrgAeabD"
   },
   "outputs": [],
   "source": [
    "nume_col = df.select_dtypes('number').columns.tolist()\n",
    "cate_col = df.select_dtypes('object').columns.tolist()\n",
    "label_col = 'quality'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "d5_q6gnQlqsU"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "gVS-juNpl4PY"
   },
   "outputs": [],
   "source": [
    "X_train, X_test = train_test_split(\n",
    "    df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "HOME_DIR = os.getcwd()\n",
    "DATA_DIR = os.path.join(HOME_DIR, 'data')\n",
    "if not os.path.isdir(DATA_DIR):\n",
    "        os.mkdir(DATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "W_VK5wSEi2_s"
   },
   "outputs": [],
   "source": [
    "out_dir = os.path.join(DATA_DIR, 'data_offline')\n",
    "if not os.path.isdir(out_dir):\n",
    "        os.mkdir(out_dir)\n",
    "threshold = 10\n",
    "thresrate = 0.99\n",
    "num_bins = 32\n",
    "test_csv_path = os.path.join(out_dir, 'test.csv')\n",
    "train_csv_path = os.path.join(out_dir, 'train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "8L8hGzG6mY6C"
   },
   "outputs": [],
   "source": [
    "X_train.to_csv(train_csv_path)\n",
    "X_test.to_csv(test_csv_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8K4GXL63nCRi"
   },
   "source": [
    "## Numeric feature preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SDbCabK1iyUv",
    "outputId": "e0308de2-6803-464d-852d-36cfc91f6184"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------\n",
      "Fitting and Transforming /home/iloncka/Documents/neurotrees/articles code reproduction/DeepGBM/data/data_offline/train.csv .\n",
      "----------------------------------------------------------------------\n",
      "Filtering and fillna features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 917.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ordinal encoding cate features\n",
      "Target encoding cate features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start manual binary encode\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 20.31it/s]\n",
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------\n",
      "Transforming /home/iloncka/Documents/neurotrees/articles code reproduction/DeepGBM/data/data_offline/test.csv .\n",
      "----------------------------------------------------------------------\n",
      "Filtering and fillna features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 1570.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ordinal encoding cate features\n",
      "Target encoding cate features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start manual binary encode\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 21.11it/s]\n",
      "0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "out_dir_num = os.path.join(DATA_DIR, 'data_offline_num')\n",
    "if not os.path.isdir(out_dir_num):\n",
    "        os.mkdir(out_dir_num)\n",
    "ec = NumEncoder(cate_col, nume_col, threshold, thresrate, label_col)\n",
    "ec.fit_transform(train_csv_path, out_dir_num + '/train')\n",
    "ec.transform(test_csv_path, out_dir_num + '/test')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lN3EOXNEnMK5"
   },
   "source": [
    "## Categorical features preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wBlXAqN2m_eZ",
    "outputId": "522d3048-998b-4acb-ad8d-246962292b86"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------\n",
      "Fitting and Transforming /home/iloncka/Documents/neurotrees/articles code reproduction/DeepGBM/data/data_offline/train.csv .\n",
      "----------------------------------------------------------------------\n",
      "Filtering and fillna features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fillna and Bucketize numeric features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 381.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ordinal encoding cate features\n",
      "----------------------------------------------------------------------\n",
      "Transforming /home/iloncka/Documents/neurotrees/articles code reproduction/DeepGBM/data/data_offline/test.csv .\n",
      "----------------------------------------------------------------------\n",
      "Filtering and fillna features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 514.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ordinal encoding cate features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "out_dir_cate = os.path.join(DATA_DIR, 'data_offline_cate')\n",
    "if not os.path.isdir(out_dir_cate):\n",
    "        os.mkdir(out_dir_cate)\n",
    "ec = CateEncoder(cate_col, nume_col, threshold, thresrate, num_bins, label_col)\n",
    "ec.fit_transform(train_csv_path, out_dir_cate + '/train/')\n",
    "ec.transform(test_csv_path, out_dir_cate + '/test/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "aTS-tYG8zkk8"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, os.path.join(HOME_DIR, 'models'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C_GbWSkDsU4R",
    "outputId": "21612187-691e-4b68-85c4-a599c60bc7fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-01-23 20:29:41,509 [INFO] data loaded.\n",
      " train_x shape: (3918, 12). train_y shape: (3918, 1).\n",
      " test_x shape: (980, 12). test_y shape: (980, 1).\n",
      "loaded from data//data_offline_cate/train/.\n",
      "loaded from data//data_offline_cate/test/.\n",
      "2022-01-23 20:29:41,512 [INFO] Categorical data loaded.\n",
      " train_x shape: (3918, 12). train_y shape: (3918, 1).\n",
      " test_x shape: (980, 12). test_y shape: (980, 1).\n",
      "[LightGBM] [Info] Total Bins 1349\n",
      "[LightGBM] [Info] Number of data: 3918, number of used features: 12\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1]\tvalid_0's l2: 28.8602\n",
      "Training until validation scores don't improve for 20 rounds.\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[2]\tvalid_0's l2: 23.3746\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[3]\tvalid_0's l2: 18.9312\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[4]\tvalid_0's l2: 15.3323\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[5]\tvalid_0's l2: 12.4181\n",
      "[6]\tvalid_0's l2: 10.0927\n",
      "[7]\tvalid_0's l2: 8.17432\n",
      "[8]\tvalid_0's l2: 6.6204\n",
      "[9]\tvalid_0's l2: 5.36224\n",
      "[10]\tvalid_0's l2: 4.34353\n",
      "[11]\tvalid_0's l2: 3.51785\n",
      "[12]\tvalid_0's l2: 2.84947\n",
      "[13]\tvalid_0's l2: 2.32035\n",
      "[14]\tvalid_0's l2: 1.89044\n",
      "[15]\tvalid_0's l2: 1.53176\n",
      "[16]\tvalid_0's l2: 1.2411\n",
      "[17]\tvalid_0's l2: 1.006\n",
      "[18]\tvalid_0's l2: 0.815457\n",
      "[19]\tvalid_0's l2: 0.661149\n",
      "[20]\tvalid_0's l2: 0.536325\n",
      "[21]\tvalid_0's l2: 0.435143\n",
      "[22]\tvalid_0's l2: 0.355798\n",
      "[23]\tvalid_0's l2: 0.289072\n",
      "[24]\tvalid_0's l2: 0.234945\n",
      "[25]\tvalid_0's l2: 0.19292\n",
      "[26]\tvalid_0's l2: 0.157193\n",
      "[27]\tvalid_0's l2: 0.128321\n",
      "[28]\tvalid_0's l2: 0.104879\n",
      "[29]\tvalid_0's l2: 0.085969\n",
      "[30]\tvalid_0's l2: 0.0706291\n",
      "[31]\tvalid_0's l2: 0.0581826\n",
      "[32]\tvalid_0's l2: 0.0481455\n",
      "[33]\tvalid_0's l2: 0.0400125\n",
      "[34]\tvalid_0's l2: 0.0334011\n",
      "[35]\tvalid_0's l2: 0.0280634\n",
      "[36]\tvalid_0's l2: 0.0237327\n",
      "[37]\tvalid_0's l2: 0.0202725\n",
      "[38]\tvalid_0's l2: 0.0174394\n",
      "[39]\tvalid_0's l2: 0.0151574\n",
      "[40]\tvalid_0's l2: 0.0133604\n",
      "[41]\tvalid_0's l2: 0.0118826\n",
      "[42]\tvalid_0's l2: 0.0106659\n",
      "[43]\tvalid_0's l2: 0.00974625\n",
      "[44]\tvalid_0's l2: 0.00892071\n",
      "[45]\tvalid_0's l2: 0.00828114\n",
      "[46]\tvalid_0's l2: 0.00775478\n",
      "[47]\tvalid_0's l2: 0.00734878\n",
      "[48]\tvalid_0's l2: 0.0070255\n",
      "[49]\tvalid_0's l2: 0.00680749\n",
      "[50]\tvalid_0's l2: 0.00657801\n",
      "[51]\tvalid_0's l2: 0.00640597\n",
      "[52]\tvalid_0's l2: 0.00628913\n",
      "[53]\tvalid_0's l2: 0.00619658\n",
      "[54]\tvalid_0's l2: 0.00611129\n",
      "[55]\tvalid_0's l2: 0.00600852\n",
      "[56]\tvalid_0's l2: 0.00595943\n",
      "[57]\tvalid_0's l2: 0.00588267\n",
      "[58]\tvalid_0's l2: 0.00585195\n",
      "[59]\tvalid_0's l2: 0.00576745\n",
      "[60]\tvalid_0's l2: 0.00574538\n",
      "[61]\tvalid_0's l2: 0.00570889\n",
      "[62]\tvalid_0's l2: 0.00568758\n",
      "[63]\tvalid_0's l2: 0.00565424\n",
      "[64]\tvalid_0's l2: 0.00564084\n",
      "[65]\tvalid_0's l2: 0.00559572\n",
      "[66]\tvalid_0's l2: 0.00557614\n",
      "[67]\tvalid_0's l2: 0.00558327\n",
      "[68]\tvalid_0's l2: 0.00558008\n",
      "[69]\tvalid_0's l2: 0.00557734\n",
      "[70]\tvalid_0's l2: 0.00553099\n",
      "[71]\tvalid_0's l2: 0.00556286\n",
      "[72]\tvalid_0's l2: 0.00553455\n",
      "[73]\tvalid_0's l2: 0.00552231\n",
      "[74]\tvalid_0's l2: 0.00551154\n",
      "[75]\tvalid_0's l2: 0.00550066\n",
      "[76]\tvalid_0's l2: 0.00550182\n",
      "[77]\tvalid_0's l2: 0.00551161\n",
      "[78]\tvalid_0's l2: 0.0055286\n",
      "[79]\tvalid_0's l2: 0.00547652\n",
      "[80]\tvalid_0's l2: 0.00543651\n",
      "[81]\tvalid_0's l2: 0.00540197\n",
      "[82]\tvalid_0's l2: 0.00541317\n",
      "[83]\tvalid_0's l2: 0.00540328\n",
      "[84]\tvalid_0's l2: 0.00540826\n",
      "[85]\tvalid_0's l2: 0.00540427\n",
      "[86]\tvalid_0's l2: 0.00544133\n",
      "[87]\tvalid_0's l2: 0.00547701\n",
      "[88]\tvalid_0's l2: 0.0054919\n",
      "[89]\tvalid_0's l2: 0.00549112\n",
      "[90]\tvalid_0's l2: 0.00549627\n",
      "[91]\tvalid_0's l2: 0.00547389\n",
      "[92]\tvalid_0's l2: 0.00547925\n",
      "[93]\tvalid_0's l2: 0.00550259\n",
      "[94]\tvalid_0's l2: 0.00550739\n",
      "[95]\tvalid_0's l2: 0.00552155\n",
      "[96]\tvalid_0's l2: 0.00551727\n",
      "[97]\tvalid_0's l2: 0.00547091\n",
      "[98]\tvalid_0's l2: 0.00542945\n",
      "[99]\tvalid_0's l2: 0.00542732\n",
      "[100]\tvalid_0's l2: 0.00542483\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[81]\tvalid_0's l2: 0.00540197\n",
      "Model Interpreting...\n",
      "[(17,), (16,), (16,), (16,), (16,)]\n",
      "emb-Evaluate Result:\n",
      "Epoch-000     8 Batches, Step      8, Testing Loss: 33.805198, Used Time:   0.0m, Remaining Time:   0.0m\n",
      "-------------------------------------------------------------------------------\n",
      "Best Metric: 33.80519828017877\n",
      "####################################################################################\n",
      "emb-Evaluate Result:\n",
      "Epoch-001     8 Batches, Step     16, Testing Loss: 31.302073, Used Time:   0.0m, Remaining Time:   0.0m\n",
      "-------------------------------------------------------------------------------\n",
      "Best Metric: 31.302073264608577\n",
      "####################################################################################\n",
      "Final Best Metric: 31.302073264608577\n",
      "Init GBDT2NN\n",
      "Init GBDT2NN succeed!\n",
      "Cuda is not available, automatically changed into cpu model\n",
      "The model is deepfm(fm+deep layers)\n",
      "Init fm part\n",
      "Init fm part succeed\n",
      "Init deep part\n",
      "Init deep part succeed\n",
      "Init succeed\n",
      "Init DeepGBM succeed!\n",
      "Alpha: Parameter containing:\n",
      "tensor(0., requires_grad=True)\n",
      "Beta: Parameter containing:\n",
      "tensor(0., requires_grad=True)\n",
      "Evaluate Result:\n",
      "Epoch-000     8 Batches, Step      8, Testing Loss: 25.340603, Used Time:   0.0m, Remaining Time:   0.2m\n",
      "-------------------------------------------------------------------------------\n",
      "Best Metric: 25.340602835830378\n",
      "####################################################################################\n",
      "Alpha: Parameter containing:\n",
      "tensor(0., requires_grad=True)\n",
      "Beta: Parameter containing:\n",
      "tensor(0., requires_grad=True)\n",
      "Evaluate Result:\n",
      "Epoch-001     8 Batches, Step     16, Testing Loss: 22.381096, Used Time:   0.0m, Remaining Time:   0.1m\n",
      "-------------------------------------------------------------------------------\n",
      "Best Metric: 22.381095535901128\n",
      "####################################################################################\n",
      "Alpha: Parameter containing:\n",
      "tensor(0.0069, requires_grad=True)\n",
      "Beta: Parameter containing:\n",
      "tensor(0.0066, requires_grad=True)\n",
      "Evaluate Result:\n",
      "Epoch-002     8 Batches, Step     24, Testing Loss:  4.255684, Used Time:   0.0m, Remaining Time:   0.1m\n",
      "-------------------------------------------------------------------------------\n",
      "Best Metric: 4.255683650775832\n",
      "####################################################################################\n",
      "Alpha: Parameter containing:\n",
      "tensor(0.0123, requires_grad=True)\n",
      "Beta: Parameter containing:\n",
      "tensor(0.0120, requires_grad=True)\n",
      "Evaluate Result:\n",
      "Epoch-003     8 Batches, Step     32, Testing Loss:  0.585829, Used Time:   0.0m, Remaining Time:   0.1m\n",
      "-------------------------------------------------------------------------------\n",
      "Best Metric: 0.5858294240065983\n",
      "####################################################################################\n",
      "Alpha: Parameter containing:\n",
      "tensor(0.0073, requires_grad=True)\n",
      "Beta: Parameter containing:\n",
      "tensor(0.0097, requires_grad=True)\n",
      "Evaluate Result:\n",
      "Epoch-004     8 Batches, Step     40, Testing Loss:  0.778072, Used Time:   0.0m, Remaining Time:   0.1m\n",
      "-------------------------------------------------------------------------------\n",
      "Best Metric: 0.5858294240065983\n",
      "####################################################################################\n",
      "Alpha: Parameter containing:\n",
      "tensor(0.0065, requires_grad=True)\n",
      "Beta: Parameter containing:\n",
      "tensor(0.0096, requires_grad=True)\n",
      "Evaluate Result:\n",
      "Epoch-005     8 Batches, Step     48, Testing Loss:  0.797459, Used Time:   0.1m, Remaining Time:   0.1m\n",
      "-------------------------------------------------------------------------------\n",
      "Best Metric: 0.5858294240065983\n",
      "####################################################################################\n",
      "Alpha: Parameter containing:\n",
      "tensor(0.0099, requires_grad=True)\n",
      "Beta: Parameter containing:\n",
      "tensor(0.0119, requires_grad=True)\n",
      "Evaluate Result:\n",
      "Epoch-006     8 Batches, Step     56, Testing Loss:  0.270042, Used Time:   0.1m, Remaining Time:   0.1m\n",
      "-------------------------------------------------------------------------------\n",
      "Best Metric: 0.2700419194844304\n",
      "####################################################################################\n",
      "Alpha: Parameter containing:\n",
      "tensor(0.0094, requires_grad=True)\n",
      "Beta: Parameter containing:\n",
      "tensor(0.0114, requires_grad=True)\n",
      "Evaluate Result:\n",
      "Epoch-007     8 Batches, Step     64, Testing Loss:  0.331800, Used Time:   0.1m, Remaining Time:   0.1m\n",
      "-------------------------------------------------------------------------------\n",
      "Best Metric: 0.2700419194844304\n",
      "####################################################################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha: Parameter containing:\n",
      "tensor(0.0109, requires_grad=True)\n",
      "Beta: Parameter containing:\n",
      "tensor(0.0124, requires_grad=True)\n",
      "Evaluate Result:\n",
      "Epoch-008     8 Batches, Step     72, Testing Loss:  0.264411, Used Time:   0.1m, Remaining Time:   0.1m\n",
      "-------------------------------------------------------------------------------\n",
      "Best Metric: 0.2644107317437931\n",
      "####################################################################################\n",
      "Alpha: Parameter containing:\n",
      "tensor(0.0126, requires_grad=True)\n",
      "Beta: Parameter containing:\n",
      "tensor(0.0134, requires_grad=True)\n",
      "Evaluate Result:\n",
      "Epoch-009     8 Batches, Step     80, Testing Loss:  0.222245, Used Time:   0.1m, Remaining Time:   0.1m\n",
      "-------------------------------------------------------------------------------\n",
      "Best Metric: 0.22224532037365194\n",
      "####################################################################################\n",
      "Alpha: Parameter containing:\n",
      "tensor(0.0133, requires_grad=True)\n",
      "Beta: Parameter containing:\n",
      "tensor(0.0138, requires_grad=True)\n",
      "Evaluate Result:\n",
      "Epoch-010     8 Batches, Step     88, Testing Loss:  0.253679, Used Time:   0.1m, Remaining Time:   0.1m\n",
      "-------------------------------------------------------------------------------\n",
      "Best Metric: 0.22224532037365194\n",
      "####################################################################################\n",
      "Alpha: Parameter containing:\n",
      "tensor(0.0153, requires_grad=True)\n",
      "Beta: Parameter containing:\n",
      "tensor(0.0153, requires_grad=True)\n",
      "Evaluate Result:\n",
      "Epoch-011     8 Batches, Step     96, Testing Loss:  0.174816, Used Time:   0.1m, Remaining Time:   0.1m\n",
      "-------------------------------------------------------------------------------\n",
      "Best Metric: 0.17481594517522928\n",
      "####################################################################################\n",
      "Alpha: Parameter containing:\n",
      "tensor(0.0166, requires_grad=True)\n",
      "Beta: Parameter containing:\n",
      "tensor(0.0162, requires_grad=True)\n",
      "Evaluate Result:\n",
      "Epoch-012     8 Batches, Step    104, Testing Loss:  0.233219, Used Time:   0.1m, Remaining Time:   0.1m\n",
      "-------------------------------------------------------------------------------\n",
      "Best Metric: 0.17481594517522928\n",
      "####################################################################################\n",
      "Alpha: Parameter containing:\n",
      "tensor(0.0184, requires_grad=True)\n",
      "Beta: Parameter containing:\n",
      "tensor(0.0177, requires_grad=True)\n",
      "Evaluate Result:\n",
      "Epoch-013     8 Batches, Step    112, Testing Loss:  0.177763, Used Time:   0.1m, Remaining Time:   0.1m\n",
      "-------------------------------------------------------------------------------\n",
      "Best Metric: 0.17481594517522928\n",
      "####################################################################################\n",
      "Alpha: Parameter containing:\n",
      "tensor(0.0199, requires_grad=True)\n",
      "Beta: Parameter containing:\n",
      "tensor(0.0193, requires_grad=True)\n",
      "Evaluate Result:\n",
      "Epoch-014     8 Batches, Step    120, Testing Loss:  0.180842, Used Time:   0.1m, Remaining Time:   0.0m\n",
      "-------------------------------------------------------------------------------\n",
      "Best Metric: 0.17481594517522928\n",
      "####################################################################################\n",
      "Alpha: Parameter containing:\n",
      "tensor(0.0215, requires_grad=True)\n",
      "Beta: Parameter containing:\n",
      "tensor(0.0213, requires_grad=True)\n",
      "Evaluate Result:\n",
      "Epoch-015     8 Batches, Step    128, Testing Loss:  0.185511, Used Time:   0.1m, Remaining Time:   0.0m\n",
      "-------------------------------------------------------------------------------\n",
      "Best Metric: 0.17481594517522928\n",
      "####################################################################################\n",
      "Alpha: Parameter containing:\n",
      "tensor(0.0230, requires_grad=True)\n",
      "Beta: Parameter containing:\n",
      "tensor(0.0236, requires_grad=True)\n",
      "Evaluate Result:\n",
      "Epoch-016     8 Batches, Step    136, Testing Loss:  0.186101, Used Time:   0.2m, Remaining Time:   0.0m\n",
      "-------------------------------------------------------------------------------\n",
      "Best Metric: 0.17481594517522928\n",
      "####################################################################################\n",
      "Alpha: Parameter containing:\n",
      "tensor(0.0244, requires_grad=True)\n",
      "Beta: Parameter containing:\n",
      "tensor(0.0266, requires_grad=True)\n",
      "Evaluate Result:\n",
      "Epoch-017     8 Batches, Step    144, Testing Loss:  0.178768, Used Time:   0.2m, Remaining Time:   0.0m\n",
      "-------------------------------------------------------------------------------\n",
      "Best Metric: 0.17481594517522928\n",
      "####################################################################################\n",
      "Alpha: Parameter containing:\n",
      "tensor(0.0255, requires_grad=True)\n",
      "Beta: Parameter containing:\n",
      "tensor(0.0287, requires_grad=True)\n",
      "Evaluate Result:\n",
      "Epoch-018     8 Batches, Step    152, Testing Loss:  0.197591, Used Time:   0.2m, Remaining Time:   0.0m\n",
      "-------------------------------------------------------------------------------\n",
      "Best Metric: 0.17481594517522928\n",
      "####################################################################################\n",
      "Alpha: Parameter containing:\n",
      "tensor(0.0264, requires_grad=True)\n",
      "Beta: Parameter containing:\n",
      "tensor(0.0314, requires_grad=True)\n",
      "Evaluate Result:\n",
      "Epoch-019     8 Batches, Step    160, Testing Loss:  0.196305, Used Time:   0.2m, Remaining Time:   0.0m\n",
      "-------------------------------------------------------------------------------\n",
      "Best Metric: 0.17481594517522928\n",
      "####################################################################################\n",
      "Final Best Metric: 0.17481594517522928\n",
      "Final metrics: 0.19630511\n",
      "Init GBDT2NN\n",
      "Init GBDT2NN succeed!\n",
      "Cuda is not available, automatically changed into cpu model\n",
      "The model is deepfm(fm+deep layers)\n",
      "Init fm part\n",
      "Init fm part succeed\n",
      "Init deep part\n",
      "Init deep part succeed\n",
      "Init succeed\n",
      "Init DeepGBM succeed!\n",
      "Alpha: Parameter containing:\n",
      "tensor(0., requires_grad=True)\n",
      "Beta: Parameter containing:\n",
      "tensor(0., requires_grad=True)\n",
      "Evaluate Result:\n",
      "Epoch-000     8 Batches, Step      8, Testing Loss: 39.584018, Used Time:   0.0m, Remaining Time:   0.2m\n",
      "-------------------------------------------------------------------------------\n",
      "Best Metric: 39.58401769521285\n",
      "####################################################################################\n",
      "Alpha: Parameter containing:\n",
      "tensor(0., requires_grad=True)\n",
      "Beta: Parameter containing:\n",
      "tensor(0., requires_grad=True)\n",
      "Evaluate Result:\n",
      "Epoch-001     8 Batches, Step     16, Testing Loss: 41.366217, Used Time:   0.0m, Remaining Time:   0.2m\n",
      "-------------------------------------------------------------------------------\n",
      "Best Metric: 39.58401769521285\n",
      "####################################################################################\n",
      "Alpha: Parameter containing:\n",
      "tensor(-0.0012, requires_grad=True)\n",
      "Beta: Parameter containing:\n",
      "tensor(0.0067, requires_grad=True)\n",
      "Evaluate Result:\n",
      "Epoch-002     8 Batches, Step     24, Testing Loss: 11.754481, Used Time:   0.0m, Remaining Time:   0.2m\n",
      "-------------------------------------------------------------------------------\n",
      "Best Metric: 11.754481296150052\n",
      "####################################################################################\n",
      "Alpha: Parameter containing:\n",
      "tensor(0.0049, requires_grad=True)\n",
      "Beta: Parameter containing:\n",
      "tensor(0.0141, requires_grad=True)\n",
      "Evaluate Result:\n",
      "Epoch-003     8 Batches, Step     32, Testing Loss:  0.886136, Used Time:   0.0m, Remaining Time:   0.2m\n",
      "-------------------------------------------------------------------------------\n",
      "Best Metric: 0.8861357216932335\n",
      "####################################################################################\n",
      "Alpha: Parameter containing:\n",
      "tensor(-0.0001, requires_grad=True)\n",
      "Beta: Parameter containing:\n",
      "tensor(0.0110, requires_grad=True)\n",
      "Evaluate Result:\n",
      "Epoch-004     8 Batches, Step     40, Testing Loss:  0.628541, Used Time:   0.0m, Remaining Time:   0.1m\n",
      "-------------------------------------------------------------------------------\n",
      "Best Metric: 0.6285412074351797\n",
      "####################################################################################\n",
      "Alpha: Parameter containing:\n",
      "tensor(-0.0056, requires_grad=True)\n",
      "Beta: Parameter containing:\n",
      "tensor(0.0067, requires_grad=True)\n",
      "Evaluate Result:\n",
      "Epoch-005     8 Batches, Step     48, Testing Loss:  1.223455, Used Time:   0.1m, Remaining Time:   0.1m\n",
      "-------------------------------------------------------------------------------\n",
      "Best Metric: 0.6285412074351797\n",
      "####################################################################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha: Parameter containing:\n",
      "tensor(-0.0037, requires_grad=True)\n",
      "Beta: Parameter containing:\n",
      "tensor(0.0069, requires_grad=True)\n",
      "Evaluate Result:\n",
      "Epoch-006     8 Batches, Step     56, Testing Loss:  0.408780, Used Time:   0.1m, Remaining Time:   0.1m\n",
      "-------------------------------------------------------------------------------\n",
      "Best Metric: 0.40877991793107016\n",
      "####################################################################################\n",
      "Alpha: Parameter containing:\n",
      "tensor(-0.0018, requires_grad=True)\n",
      "Beta: Parameter containing:\n",
      "tensor(0.0073, requires_grad=True)\n",
      "Evaluate Result:\n",
      "Epoch-007     8 Batches, Step     64, Testing Loss:  0.250769, Used Time:   0.1m, Remaining Time:   0.1m\n",
      "-------------------------------------------------------------------------------\n",
      "Best Metric: 0.2507689774644618\n",
      "####################################################################################\n",
      "Alpha: Parameter containing:\n",
      "tensor(-0.0021, requires_grad=True)\n",
      "Beta: Parameter containing:\n",
      "tensor(0.0068, requires_grad=True)\n",
      "Evaluate Result:\n",
      "Epoch-008     8 Batches, Step     72, Testing Loss:  0.275987, Used Time:   0.1m, Remaining Time:   0.1m\n",
      "-------------------------------------------------------------------------------\n",
      "Best Metric: 0.2507689774644618\n",
      "####################################################################################\n",
      "Alpha: Parameter containing:\n",
      "tensor(-0.0004, requires_grad=True)\n",
      "Beta: Parameter containing:\n",
      "tensor(0.0074, requires_grad=True)\n",
      "Evaluate Result:\n",
      "Epoch-009     8 Batches, Step     80, Testing Loss:  0.230868, Used Time:   0.1m, Remaining Time:   0.1m\n",
      "-------------------------------------------------------------------------------\n",
      "Best Metric: 0.23086817927506506\n",
      "####################################################################################\n",
      "Alpha: Parameter containing:\n",
      "tensor(0.0012, requires_grad=True)\n",
      "Beta: Parameter containing:\n",
      "tensor(0.0081, requires_grad=True)\n",
      "Evaluate Result:\n",
      "Epoch-010     8 Batches, Step     88, Testing Loss:  0.200337, Used Time:   0.1m, Remaining Time:   0.1m\n",
      "-------------------------------------------------------------------------------\n",
      "Best Metric: 0.2003365697301164\n",
      "####################################################################################\n",
      "Alpha: Parameter containing:\n",
      "tensor(0.0024, requires_grad=True)\n",
      "Beta: Parameter containing:\n",
      "tensor(0.0083, requires_grad=True)\n",
      "Evaluate Result:\n",
      "Epoch-011     8 Batches, Step     96, Testing Loss:  0.206399, Used Time:   0.1m, Remaining Time:   0.1m\n",
      "-------------------------------------------------------------------------------\n",
      "Best Metric: 0.2003365697301164\n",
      "####################################################################################\n",
      "Alpha: Parameter containing:\n",
      "tensor(0.0042, requires_grad=True)\n",
      "Beta: Parameter containing:\n",
      "tensor(0.0091, requires_grad=True)\n",
      "Evaluate Result:\n",
      "Epoch-012     8 Batches, Step    104, Testing Loss:  0.194930, Used Time:   0.1m, Remaining Time:   0.1m\n",
      "-------------------------------------------------------------------------------\n",
      "Best Metric: 0.19493042540793515\n",
      "####################################################################################\n",
      "Alpha: Parameter containing:\n",
      "tensor(0.0059, requires_grad=True)\n",
      "Beta: Parameter containing:\n",
      "tensor(0.0097, requires_grad=True)\n",
      "Evaluate Result:\n",
      "Epoch-013     8 Batches, Step    112, Testing Loss:  0.188016, Used Time:   0.2m, Remaining Time:   0.1m\n",
      "-------------------------------------------------------------------------------\n",
      "Best Metric: 0.18801604545846276\n",
      "####################################################################################\n",
      "Alpha: Parameter containing:\n",
      "tensor(0.0076, requires_grad=True)\n",
      "Beta: Parameter containing:\n",
      "tensor(0.0102, requires_grad=True)\n",
      "Evaluate Result:\n",
      "Epoch-014     8 Batches, Step    120, Testing Loss:  0.163277, Used Time:   0.2m, Remaining Time:   0.1m\n",
      "-------------------------------------------------------------------------------\n",
      "Best Metric: 0.16327712031043307\n",
      "####################################################################################\n",
      "Alpha: Parameter containing:\n",
      "tensor(0.0095, requires_grad=True)\n",
      "Beta: Parameter containing:\n",
      "tensor(0.0109, requires_grad=True)\n",
      "Evaluate Result:\n",
      "Epoch-015     8 Batches, Step    128, Testing Loss:  0.171449, Used Time:   0.2m, Remaining Time:   0.0m\n",
      "-------------------------------------------------------------------------------\n",
      "Best Metric: 0.16327712031043307\n",
      "####################################################################################\n",
      "Alpha: Parameter containing:\n",
      "tensor(0.0112, requires_grad=True)\n",
      "Beta: Parameter containing:\n",
      "tensor(0.0117, requires_grad=True)\n",
      "Evaluate Result:\n",
      "Epoch-016     8 Batches, Step    136, Testing Loss:  0.175013, Used Time:   0.2m, Remaining Time:   0.0m\n",
      "-------------------------------------------------------------------------------\n",
      "Best Metric: 0.16327712031043307\n",
      "####################################################################################\n",
      "Alpha: Parameter containing:\n",
      "tensor(0.0133, requires_grad=True)\n",
      "Beta: Parameter containing:\n",
      "tensor(0.0129, requires_grad=True)\n",
      "Evaluate Result:\n",
      "Epoch-017     8 Batches, Step    144, Testing Loss:  0.180872, Used Time:   0.2m, Remaining Time:   0.0m\n",
      "-------------------------------------------------------------------------------\n",
      "Best Metric: 0.16327712031043307\n",
      "####################################################################################\n",
      "Alpha: Parameter containing:\n",
      "tensor(0.0149, requires_grad=True)\n",
      "Beta: Parameter containing:\n",
      "tensor(0.0138, requires_grad=True)\n",
      "Evaluate Result:\n",
      "Epoch-018     8 Batches, Step    152, Testing Loss:  0.172699, Used Time:   0.2m, Remaining Time:   0.0m\n",
      "-------------------------------------------------------------------------------\n",
      "Best Metric: 0.16327712031043307\n",
      "####################################################################################\n",
      "Alpha: Parameter containing:\n",
      "tensor(0.0169, requires_grad=True)\n",
      "Beta: Parameter containing:\n",
      "tensor(0.0157, requires_grad=True)\n",
      "Evaluate Result:\n",
      "Epoch-019     8 Batches, Step    160, Testing Loss:  0.160368, Used Time:   0.2m, Remaining Time:   0.0m\n",
      "-------------------------------------------------------------------------------\n",
      "Best Metric: 0.16036843280402982\n",
      "####################################################################################\n",
      "Final Best Metric: 0.16036843280402982\n",
      "Final metrics: 0.16036844\n",
      "Init GBDT2NN\n",
      "Init GBDT2NN succeed!\n",
      "Cuda is not available, automatically changed into cpu model\n",
      "The model is deepfm(fm+deep layers)\n",
      "Init fm part\n",
      "Init fm part succeed\n",
      "Init deep part\n",
      "Init deep part succeed\n",
      "Init succeed\n",
      "Init DeepGBM succeed!\n",
      "Alpha: Parameter containing:\n",
      "tensor(0., requires_grad=True)\n",
      "Beta: Parameter containing:\n",
      "tensor(0., requires_grad=True)\n",
      "Evaluate Result:\n",
      "Epoch-000     8 Batches, Step      8, Testing Loss: 34.926187, Used Time:   0.0m, Remaining Time:   0.2m\n",
      "-------------------------------------------------------------------------------\n",
      "Best Metric: 34.92618700922752\n",
      "####################################################################################\n",
      "Alpha: Parameter containing:\n",
      "tensor(0., requires_grad=True)\n",
      "Beta: Parameter containing:\n",
      "tensor(0., requires_grad=True)\n",
      "Evaluate Result:\n",
      "Epoch-001     8 Batches, Step     16, Testing Loss: 35.049292, Used Time:   0.0m, Remaining Time:   0.2m\n",
      "-------------------------------------------------------------------------------\n",
      "Best Metric: 34.92618700922752\n",
      "####################################################################################\n",
      "Alpha: Parameter containing:\n",
      "tensor(0.0067, requires_grad=True)\n",
      "Beta: Parameter containing:\n",
      "tensor(0.0068, requires_grad=True)\n",
      "Evaluate Result:\n",
      "Epoch-002     8 Batches, Step     24, Testing Loss:  8.654690, Used Time:   0.0m, Remaining Time:   0.2m\n",
      "-------------------------------------------------------------------------------\n",
      "Best Metric: 8.654690051565366\n",
      "####################################################################################\n",
      "Alpha: Parameter containing:\n",
      "tensor(0.0131, requires_grad=True)\n",
      "Beta: Parameter containing:\n",
      "tensor(0.0130, requires_grad=True)\n",
      "Evaluate Result:\n",
      "Epoch-003     8 Batches, Step     32, Testing Loss:  0.957110, Used Time:   0.0m, Remaining Time:   0.2m\n",
      "-------------------------------------------------------------------------------\n",
      "Best Metric: 0.9571099196161542\n",
      "####################################################################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha: Parameter containing:\n",
      "tensor(0.0078, requires_grad=True)\n",
      "Beta: Parameter containing:\n",
      "tensor(0.0105, requires_grad=True)\n",
      "Evaluate Result:\n",
      "Epoch-004     8 Batches, Step     40, Testing Loss:  0.847127, Used Time:   0.1m, Remaining Time:   0.2m\n",
      "-------------------------------------------------------------------------------\n",
      "Best Metric: 0.8471269072318564\n",
      "####################################################################################\n",
      "Alpha: Parameter containing:\n",
      "tensor(0.0053, requires_grad=True)\n",
      "Beta: Parameter containing:\n",
      "tensor(0.0091, requires_grad=True)\n",
      "Evaluate Result:\n",
      "Epoch-005     8 Batches, Step     48, Testing Loss:  1.175847, Used Time:   0.1m, Remaining Time:   0.2m\n",
      "-------------------------------------------------------------------------------\n",
      "Best Metric: 0.8471269072318564\n",
      "####################################################################################\n",
      "Alpha: Parameter containing:\n",
      "tensor(0.0086, requires_grad=True)\n",
      "Beta: Parameter containing:\n",
      "tensor(0.0112, requires_grad=True)\n",
      "Evaluate Result:\n",
      "Epoch-006     8 Batches, Step     56, Testing Loss:  0.343899, Used Time:   0.1m, Remaining Time:   0.1m\n",
      "-------------------------------------------------------------------------------\n",
      "Best Metric: 0.34389931875832225\n",
      "####################################################################################\n",
      "Alpha: Parameter containing:\n",
      "tensor(0.0090, requires_grad=True)\n",
      "Beta: Parameter containing:\n",
      "tensor(0.0113, requires_grad=True)\n",
      "Evaluate Result:\n",
      "Epoch-007     8 Batches, Step     64, Testing Loss:  0.343128, Used Time:   0.1m, Remaining Time:   0.1m\n",
      "-------------------------------------------------------------------------------\n",
      "Best Metric: 0.3431282250248656\n",
      "####################################################################################\n",
      "Alpha: Parameter containing:\n",
      "tensor(0.0095, requires_grad=True)\n",
      "Beta: Parameter containing:\n",
      "tensor(0.0115, requires_grad=True)\n",
      "Evaluate Result:\n",
      "Epoch-008     8 Batches, Step     72, Testing Loss:  0.345425, Used Time:   0.1m, Remaining Time:   0.1m\n",
      "-------------------------------------------------------------------------------\n",
      "Best Metric: 0.3431282250248656\n",
      "####################################################################################\n",
      "Alpha: Parameter containing:\n",
      "tensor(0.0117, requires_grad=True)\n",
      "Beta: Parameter containing:\n",
      "tensor(0.0131, requires_grad=True)\n",
      "Evaluate Result:\n",
      "Epoch-009     8 Batches, Step     80, Testing Loss:  0.235467, Used Time:   0.1m, Remaining Time:   0.1m\n",
      "-------------------------------------------------------------------------------\n",
      "Best Metric: 0.23546672353939135\n",
      "####################################################################################\n",
      "Alpha: Parameter containing:\n",
      "tensor(0.0124, requires_grad=True)\n",
      "Beta: Parameter containing:\n",
      "tensor(0.0134, requires_grad=True)\n",
      "Evaluate Result:\n",
      "Epoch-010     8 Batches, Step     88, Testing Loss:  0.224595, Used Time:   0.1m, Remaining Time:   0.1m\n",
      "-------------------------------------------------------------------------------\n",
      "Best Metric: 0.22459476912508206\n",
      "####################################################################################\n",
      "Alpha: Parameter containing:\n",
      "tensor(0.0143, requires_grad=True)\n",
      "Beta: Parameter containing:\n",
      "tensor(0.0148, requires_grad=True)\n",
      "Evaluate Result:\n",
      "Epoch-011     8 Batches, Step     96, Testing Loss:  0.201239, Used Time:   0.1m, Remaining Time:   0.1m\n",
      "-------------------------------------------------------------------------------\n",
      "Best Metric: 0.20123884507587977\n",
      "####################################################################################\n",
      "Alpha: Parameter containing:\n",
      "tensor(0.0156, requires_grad=True)\n",
      "Beta: Parameter containing:\n",
      "tensor(0.0156, requires_grad=True)\n",
      "Evaluate Result:\n",
      "Epoch-012     8 Batches, Step    104, Testing Loss:  0.210409, Used Time:   0.1m, Remaining Time:   0.1m\n",
      "-------------------------------------------------------------------------------\n",
      "Best Metric: 0.20123884507587977\n",
      "####################################################################################\n",
      "Alpha: Parameter containing:\n",
      "tensor(0.0173, requires_grad=True)\n",
      "Beta: Parameter containing:\n",
      "tensor(0.0169, requires_grad=True)\n",
      "Evaluate Result:\n",
      "Epoch-013     8 Batches, Step    112, Testing Loss:  0.198589, Used Time:   0.1m, Remaining Time:   0.1m\n",
      "-------------------------------------------------------------------------------\n",
      "Best Metric: 0.19858872251851217\n",
      "####################################################################################\n",
      "Alpha: Parameter containing:\n",
      "tensor(0.0190, requires_grad=True)\n",
      "Beta: Parameter containing:\n",
      "tensor(0.0185, requires_grad=True)\n",
      "Evaluate Result:\n",
      "Epoch-014     8 Batches, Step    120, Testing Loss:  0.172713, Used Time:   0.2m, Remaining Time:   0.1m\n",
      "-------------------------------------------------------------------------------\n",
      "Best Metric: 0.17271272534010362\n",
      "####################################################################################\n",
      "Alpha: Parameter containing:\n",
      "tensor(0.0206, requires_grad=True)\n",
      "Beta: Parameter containing:\n",
      "tensor(0.0203, requires_grad=True)\n",
      "Evaluate Result:\n",
      "Epoch-015     8 Batches, Step    128, Testing Loss:  0.177811, Used Time:   0.2m, Remaining Time:   0.0m\n",
      "-------------------------------------------------------------------------------\n",
      "Best Metric: 0.17271272534010362\n",
      "####################################################################################\n",
      "Alpha: Parameter containing:\n",
      "tensor(0.0222, requires_grad=True)\n",
      "Beta: Parameter containing:\n",
      "tensor(0.0228, requires_grad=True)\n",
      "Evaluate Result:\n",
      "Epoch-016     8 Batches, Step    136, Testing Loss:  0.173722, Used Time:   0.2m, Remaining Time:   0.0m\n",
      "-------------------------------------------------------------------------------\n",
      "Best Metric: 0.17271272534010362\n",
      "####################################################################################\n",
      "Alpha: Parameter containing:\n",
      "tensor(0.0235, requires_grad=True)\n",
      "Beta: Parameter containing:\n",
      "tensor(0.0251, requires_grad=True)\n",
      "Evaluate Result:\n",
      "Epoch-017     8 Batches, Step    144, Testing Loss:  0.170812, Used Time:   0.2m, Remaining Time:   0.0m\n",
      "-------------------------------------------------------------------------------\n",
      "Best Metric: 0.1708121126403614\n",
      "####################################################################################\n",
      "Alpha: Parameter containing:\n",
      "tensor(0.0247, requires_grad=True)\n",
      "Beta: Parameter containing:\n",
      "tensor(0.0276, requires_grad=True)\n",
      "Evaluate Result:\n",
      "Epoch-018     8 Batches, Step    152, Testing Loss:  0.186449, Used Time:   0.2m, Remaining Time:   0.0m\n",
      "-------------------------------------------------------------------------------\n",
      "Best Metric: 0.1708121126403614\n",
      "####################################################################################\n",
      "Alpha: Parameter containing:\n",
      "tensor(0.0258, requires_grad=True)\n",
      "Beta: Parameter containing:\n",
      "tensor(0.0309, requires_grad=True)\n",
      "Evaluate Result:\n",
      "Epoch-019     8 Batches, Step    160, Testing Loss:  0.196857, Used Time:   0.2m, Remaining Time:   0.0m\n",
      "-------------------------------------------------------------------------------\n",
      "Best Metric: 0.1708121126403614\n",
      "####################################################################################\n",
      "Final Best Metric: 0.1708121126403614\n",
      "Final metrics: 0.19685668\n",
      "Init GBDT2NN\n",
      "Init GBDT2NN succeed!\n",
      "Cuda is not available, automatically changed into cpu model\n",
      "The model is deepfm(fm+deep layers)\n",
      "Init fm part\n",
      "Init fm part succeed\n",
      "Init deep part\n",
      "Init deep part succeed\n",
      "Init succeed\n",
      "Init DeepGBM succeed!\n",
      "Alpha: Parameter containing:\n",
      "tensor(0., requires_grad=True)\n",
      "Beta: Parameter containing:\n",
      "tensor(0., requires_grad=True)\n",
      "Evaluate Result:\n",
      "Epoch-000     8 Batches, Step      8, Testing Loss: 32.589498, Used Time:   0.0m, Remaining Time:   0.2m\n",
      "-------------------------------------------------------------------------------\n",
      "Best Metric: 32.589497780313295\n",
      "####################################################################################\n",
      "Alpha: Parameter containing:\n",
      "tensor(0., requires_grad=True)\n",
      "Beta: Parameter containing:\n",
      "tensor(0., requires_grad=True)\n",
      "Evaluate Result:\n",
      "Epoch-001     8 Batches, Step     16, Testing Loss: 33.286583, Used Time:   0.0m, Remaining Time:   0.2m\n",
      "-------------------------------------------------------------------------------\n",
      "Best Metric: 32.589497780313295\n",
      "####################################################################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha: Parameter containing:\n",
      "tensor(0.0036, requires_grad=True)\n",
      "Beta: Parameter containing:\n",
      "tensor(0.0067, requires_grad=True)\n",
      "Evaluate Result:\n",
      "Epoch-002     8 Batches, Step     24, Testing Loss:  6.594897, Used Time:   0.0m, Remaining Time:   0.2m\n",
      "-------------------------------------------------------------------------------\n",
      "Best Metric: 6.594897036649743\n",
      "####################################################################################\n",
      "Alpha: Parameter containing:\n",
      "tensor(0.0103, requires_grad=True)\n",
      "Beta: Parameter containing:\n",
      "tensor(0.0132, requires_grad=True)\n",
      "Evaluate Result:\n",
      "Epoch-003     8 Batches, Step     32, Testing Loss:  0.824829, Used Time:   0.0m, Remaining Time:   0.2m\n",
      "-------------------------------------------------------------------------------\n",
      "Best Metric: 0.8248293448467644\n",
      "####################################################################################\n",
      "Alpha: Parameter containing:\n",
      "tensor(0.0050, requires_grad=True)\n",
      "Beta: Parameter containing:\n",
      "tensor(0.0098, requires_grad=True)\n",
      "Evaluate Result:\n",
      "Epoch-004     8 Batches, Step     40, Testing Loss:  0.643351, Used Time:   0.0m, Remaining Time:   0.1m\n",
      "-------------------------------------------------------------------------------\n",
      "Best Metric: 0.6433506516777739\n",
      "####################################################################################\n",
      "Alpha: Parameter containing:\n",
      "tensor(0.0013, requires_grad=True)\n",
      "Beta: Parameter containing:\n",
      "tensor(0.0068, requires_grad=True)\n",
      "Evaluate Result:\n",
      "Epoch-005     8 Batches, Step     48, Testing Loss:  1.091251, Used Time:   0.1m, Remaining Time:   0.1m\n",
      "-------------------------------------------------------------------------------\n",
      "Best Metric: 0.6433506516777739\n",
      "####################################################################################\n",
      "Alpha: Parameter containing:\n",
      "tensor(0.0045, requires_grad=True)\n",
      "Beta: Parameter containing:\n",
      "tensor(0.0078, requires_grad=True)\n",
      "Evaluate Result:\n",
      "Epoch-006     8 Batches, Step     56, Testing Loss:  0.450419, Used Time:   0.1m, Remaining Time:   0.1m\n",
      "-------------------------------------------------------------------------------\n",
      "Best Metric: 0.45041918572114437\n",
      "####################################################################################\n",
      "Alpha: Parameter containing:\n",
      "tensor(0.0054, requires_grad=True)\n",
      "Beta: Parameter containing:\n",
      "tensor(0.0078, requires_grad=True)\n",
      "Evaluate Result:\n",
      "Epoch-007     8 Batches, Step     64, Testing Loss:  0.425430, Used Time:   0.1m, Remaining Time:   0.1m\n",
      "-------------------------------------------------------------------------------\n",
      "Best Metric: 0.4254301828997476\n",
      "####################################################################################\n",
      "Alpha: Parameter containing:\n",
      "tensor(0.0054, requires_grad=True)\n",
      "Beta: Parameter containing:\n",
      "tensor(0.0074, requires_grad=True)\n",
      "Evaluate Result:\n",
      "Epoch-008     8 Batches, Step     72, Testing Loss:  0.440856, Used Time:   0.1m, Remaining Time:   0.1m\n",
      "-------------------------------------------------------------------------------\n",
      "Best Metric: 0.4254301828997476\n",
      "####################################################################################\n",
      "Alpha: Parameter containing:\n",
      "tensor(0.0076, requires_grad=True)\n",
      "Beta: Parameter containing:\n",
      "tensor(0.0082, requires_grad=True)\n",
      "Evaluate Result:\n",
      "Epoch-009     8 Batches, Step     80, Testing Loss:  0.317682, Used Time:   0.1m, Remaining Time:   0.1m\n",
      "-------------------------------------------------------------------------------\n",
      "Best Metric: 0.31768210536363173\n",
      "####################################################################################\n",
      "Alpha: Parameter containing:\n",
      "tensor(0.0085, requires_grad=True)\n",
      "Beta: Parameter containing:\n",
      "tensor(0.0081, requires_grad=True)\n",
      "Evaluate Result:\n",
      "Epoch-010     8 Batches, Step     88, Testing Loss:  0.351222, Used Time:   0.1m, Remaining Time:   0.1m\n",
      "-------------------------------------------------------------------------------\n",
      "Best Metric: 0.31768210536363173\n",
      "####################################################################################\n",
      "Alpha: Parameter containing:\n",
      "tensor(0.0101, requires_grad=True)\n",
      "Beta: Parameter containing:\n",
      "tensor(0.0087, requires_grad=True)\n",
      "Evaluate Result:\n",
      "Epoch-011     8 Batches, Step     96, Testing Loss:  0.327612, Used Time:   0.1m, Remaining Time:   0.1m\n",
      "-------------------------------------------------------------------------------\n",
      "Best Metric: 0.31768210536363173\n",
      "####################################################################################\n",
      "Alpha: Parameter containing:\n",
      "tensor(0.0119, requires_grad=True)\n",
      "Beta: Parameter containing:\n",
      "tensor(0.0096, requires_grad=True)\n",
      "Evaluate Result:\n",
      "Epoch-012     8 Batches, Step    104, Testing Loss:  0.279204, Used Time:   0.1m, Remaining Time:   0.1m\n",
      "-------------------------------------------------------------------------------\n",
      "Best Metric: 0.279204427891848\n",
      "####################################################################################\n",
      "Alpha: Parameter containing:\n",
      "tensor(0.0135, requires_grad=True)\n",
      "Beta: Parameter containing:\n",
      "tensor(0.0103, requires_grad=True)\n",
      "Evaluate Result:\n",
      "Epoch-013     8 Batches, Step    112, Testing Loss:  0.304125, Used Time:   0.1m, Remaining Time:   0.1m\n",
      "-------------------------------------------------------------------------------\n",
      "Best Metric: 0.279204427891848\n",
      "####################################################################################\n",
      "Alpha: Parameter containing:\n",
      "tensor(0.0153, requires_grad=True)\n",
      "Beta: Parameter containing:\n",
      "tensor(0.0113, requires_grad=True)\n",
      "Evaluate Result:\n",
      "Epoch-014     8 Batches, Step    120, Testing Loss:  0.259677, Used Time:   0.1m, Remaining Time:   0.0m\n",
      "-------------------------------------------------------------------------------\n",
      "Best Metric: 0.2596768958836186\n",
      "####################################################################################\n",
      "Alpha: Parameter containing:\n",
      "tensor(0.0171, requires_grad=True)\n",
      "Beta: Parameter containing:\n",
      "tensor(0.0127, requires_grad=True)\n",
      "Evaluate Result:\n",
      "Epoch-015     8 Batches, Step    128, Testing Loss:  0.268603, Used Time:   0.2m, Remaining Time:   0.0m\n",
      "-------------------------------------------------------------------------------\n",
      "Best Metric: 0.2596768958836186\n",
      "####################################################################################\n",
      "Alpha: Parameter containing:\n",
      "tensor(0.0189, requires_grad=True)\n",
      "Beta: Parameter containing:\n",
      "tensor(0.0141, requires_grad=True)\n",
      "Evaluate Result:\n",
      "Epoch-016     8 Batches, Step    136, Testing Loss:  0.282845, Used Time:   0.2m, Remaining Time:   0.0m\n",
      "-------------------------------------------------------------------------------\n",
      "Best Metric: 0.2596768958836186\n",
      "####################################################################################\n",
      "Alpha: Parameter containing:\n",
      "tensor(0.0208, requires_grad=True)\n",
      "Beta: Parameter containing:\n",
      "tensor(0.0158, requires_grad=True)\n",
      "Evaluate Result:\n",
      "Epoch-017     8 Batches, Step    144, Testing Loss:  0.283379, Used Time:   0.2m, Remaining Time:   0.0m\n",
      "-------------------------------------------------------------------------------\n",
      "Best Metric: 0.2596768958836186\n",
      "####################################################################################\n",
      "Alpha: Parameter containing:\n",
      "tensor(0.0226, requires_grad=True)\n",
      "Beta: Parameter containing:\n",
      "tensor(0.0177, requires_grad=True)\n",
      "Evaluate Result:\n",
      "Epoch-018     8 Batches, Step    152, Testing Loss:  0.261480, Used Time:   0.2m, Remaining Time:   0.0m\n",
      "-------------------------------------------------------------------------------\n",
      "Best Metric: 0.2596768958836186\n",
      "####################################################################################\n",
      "Alpha: Parameter containing:\n",
      "tensor(0.0245, requires_grad=True)\n",
      "Beta: Parameter containing:\n",
      "tensor(0.0203, requires_grad=True)\n",
      "Evaluate Result:\n",
      "Epoch-019     8 Batches, Step    160, Testing Loss:  0.238021, Used Time:   0.2m, Remaining Time:   0.0m\n",
      "-------------------------------------------------------------------------------\n",
      "Best Metric: 0.2380208500794002\n",
      "####################################################################################\n",
      "Final Best Metric: 0.2380208500794002\n",
      "Final metrics: 0.23802085\n",
      "Init GBDT2NN\n",
      "Init GBDT2NN succeed!\n",
      "Cuda is not available, automatically changed into cpu model\n",
      "The model is deepfm(fm+deep layers)\n",
      "Init fm part\n",
      "Init fm part succeed\n",
      "Init deep part\n",
      "Init deep part succeed\n",
      "Init succeed\n",
      "Init DeepGBM succeed!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha: Parameter containing:\n",
      "tensor(0., requires_grad=True)\n",
      "Beta: Parameter containing:\n",
      "tensor(0., requires_grad=True)\n",
      "Evaluate Result:\n",
      "Epoch-000     8 Batches, Step      8, Testing Loss: 30.393875, Used Time:   0.0m, Remaining Time:   0.2m\n",
      "-------------------------------------------------------------------------------\n",
      "Best Metric: 30.393875005293864\n",
      "####################################################################################\n",
      "Alpha: Parameter containing:\n",
      "tensor(0., requires_grad=True)\n",
      "Beta: Parameter containing:\n",
      "tensor(0., requires_grad=True)\n",
      "Evaluate Result:\n",
      "Epoch-001     8 Batches, Step     16, Testing Loss: 28.242369, Used Time:   0.0m, Remaining Time:   0.2m\n",
      "-------------------------------------------------------------------------------\n",
      "Best Metric: 28.242368542418188\n",
      "####################################################################################\n",
      "Alpha: Parameter containing:\n",
      "tensor(0.0069, requires_grad=True)\n",
      "Beta: Parameter containing:\n",
      "tensor(0.0066, requires_grad=True)\n",
      "Evaluate Result:\n",
      "Epoch-002     8 Batches, Step     24, Testing Loss:  6.799141, Used Time:   0.0m, Remaining Time:   0.2m\n",
      "-------------------------------------------------------------------------------\n",
      "Best Metric: 6.799140793936593\n",
      "####################################################################################\n",
      "Alpha: Parameter containing:\n",
      "tensor(0.0125, requires_grad=True)\n",
      "Beta: Parameter containing:\n",
      "tensor(0.0120, requires_grad=True)\n",
      "Evaluate Result:\n",
      "Epoch-003     8 Batches, Step     32, Testing Loss:  0.613162, Used Time:   0.0m, Remaining Time:   0.2m\n",
      "-------------------------------------------------------------------------------\n",
      "Best Metric: 0.6131617651910198\n",
      "####################################################################################\n",
      "Alpha: Parameter containing:\n",
      "tensor(0.0073, requires_grad=True)\n",
      "Beta: Parameter containing:\n",
      "tensor(0.0086, requires_grad=True)\n",
      "Evaluate Result:\n",
      "Epoch-004     8 Batches, Step     40, Testing Loss:  0.805954, Used Time:   0.0m, Remaining Time:   0.1m\n",
      "-------------------------------------------------------------------------------\n",
      "Best Metric: 0.6131617651910198\n",
      "####################################################################################\n",
      "Alpha: Parameter containing:\n",
      "tensor(0.0065, requires_grad=True)\n",
      "Beta: Parameter containing:\n",
      "tensor(0.0077, requires_grad=True)\n",
      "Evaluate Result:\n",
      "Epoch-005     8 Batches, Step     48, Testing Loss:  0.828863, Used Time:   0.1m, Remaining Time:   0.1m\n",
      "-------------------------------------------------------------------------------\n",
      "Best Metric: 0.6131617651910198\n",
      "####################################################################################\n",
      "Alpha: Parameter containing:\n",
      "tensor(0.0100, requires_grad=True)\n",
      "Beta: Parameter containing:\n",
      "tensor(0.0099, requires_grad=True)\n",
      "Evaluate Result:\n",
      "Epoch-006     8 Batches, Step     56, Testing Loss:  0.382729, Used Time:   0.1m, Remaining Time:   0.1m\n",
      "-------------------------------------------------------------------------------\n",
      "Best Metric: 0.3827289719970859\n",
      "####################################################################################\n",
      "Alpha: Parameter containing:\n",
      "tensor(0.0098, requires_grad=True)\n",
      "Beta: Parameter containing:\n",
      "tensor(0.0093, requires_grad=True)\n",
      "Evaluate Result:\n",
      "Epoch-007     8 Batches, Step     64, Testing Loss:  0.351988, Used Time:   0.1m, Remaining Time:   0.1m\n",
      "-------------------------------------------------------------------------------\n",
      "Best Metric: 0.35198804310389925\n",
      "####################################################################################\n",
      "Alpha: Parameter containing:\n",
      "tensor(0.0113, requires_grad=True)\n",
      "Beta: Parameter containing:\n",
      "tensor(0.0101, requires_grad=True)\n",
      "Evaluate Result:\n",
      "Epoch-008     8 Batches, Step     72, Testing Loss:  0.259168, Used Time:   0.1m, Remaining Time:   0.1m\n",
      "-------------------------------------------------------------------------------\n",
      "Best Metric: 0.2591683107371233\n",
      "####################################################################################\n",
      "Alpha: Parameter containing:\n",
      "tensor(0.0130, requires_grad=True)\n",
      "Beta: Parameter containing:\n",
      "tensor(0.0109, requires_grad=True)\n",
      "Evaluate Result:\n",
      "Epoch-009     8 Batches, Step     80, Testing Loss:  0.244692, Used Time:   0.1m, Remaining Time:   0.1m\n",
      "-------------------------------------------------------------------------------\n",
      "Best Metric: 0.24469234779173013\n",
      "####################################################################################\n",
      "Alpha: Parameter containing:\n",
      "tensor(0.0142, requires_grad=True)\n",
      "Beta: Parameter containing:\n",
      "tensor(0.0114, requires_grad=True)\n",
      "Evaluate Result:\n",
      "Epoch-010     8 Batches, Step     88, Testing Loss:  0.271392, Used Time:   0.1m, Remaining Time:   0.1m\n",
      "-------------------------------------------------------------------------------\n",
      "Best Metric: 0.24469234779173013\n",
      "####################################################################################\n",
      "Alpha: Parameter containing:\n",
      "tensor(0.0161, requires_grad=True)\n",
      "Beta: Parameter containing:\n",
      "tensor(0.0125, requires_grad=True)\n",
      "Evaluate Result:\n",
      "Epoch-011     8 Batches, Step     96, Testing Loss:  0.205021, Used Time:   0.1m, Remaining Time:   0.1m\n",
      "-------------------------------------------------------------------------------\n",
      "Best Metric: 0.2050212633853056\n",
      "####################################################################################\n",
      "Alpha: Parameter containing:\n",
      "tensor(0.0177, requires_grad=True)\n",
      "Beta: Parameter containing:\n",
      "tensor(0.0133, requires_grad=True)\n",
      "Evaluate Result:\n",
      "Epoch-012     8 Batches, Step    104, Testing Loss:  0.247765, Used Time:   0.1m, Remaining Time:   0.1m\n",
      "-------------------------------------------------------------------------------\n",
      "Best Metric: 0.2050212633853056\n",
      "####################################################################################\n",
      "Alpha: Parameter containing:\n",
      "tensor(0.0197, requires_grad=True)\n",
      "Beta: Parameter containing:\n",
      "tensor(0.0146, requires_grad=True)\n",
      "Evaluate Result:\n",
      "Epoch-013     8 Batches, Step    112, Testing Loss:  0.203748, Used Time:   0.1m, Remaining Time:   0.1m\n",
      "-------------------------------------------------------------------------------\n",
      "Best Metric: 0.2037476640270681\n",
      "####################################################################################\n",
      "Alpha: Parameter containing:\n",
      "tensor(0.0215, requires_grad=True)\n",
      "Beta: Parameter containing:\n",
      "tensor(0.0160, requires_grad=True)\n",
      "Evaluate Result:\n",
      "Epoch-014     8 Batches, Step    120, Testing Loss:  0.196002, Used Time:   0.1m, Remaining Time:   0.0m\n",
      "-------------------------------------------------------------------------------\n",
      "Best Metric: 0.19600224494934082\n",
      "####################################################################################\n",
      "Alpha: Parameter containing:\n",
      "tensor(0.0233, requires_grad=True)\n",
      "Beta: Parameter containing:\n",
      "tensor(0.0181, requires_grad=True)\n",
      "Evaluate Result:\n",
      "Epoch-015     8 Batches, Step    128, Testing Loss:  0.208058, Used Time:   0.2m, Remaining Time:   0.0m\n",
      "-------------------------------------------------------------------------------\n",
      "Best Metric: 0.19600224494934082\n",
      "####################################################################################\n",
      "Alpha: Parameter containing:\n",
      "tensor(0.0251, requires_grad=True)\n",
      "Beta: Parameter containing:\n",
      "tensor(0.0212, requires_grad=True)\n",
      "Evaluate Result:\n",
      "Epoch-016     8 Batches, Step    136, Testing Loss:  0.208811, Used Time:   0.2m, Remaining Time:   0.0m\n",
      "-------------------------------------------------------------------------------\n",
      "Best Metric: 0.19600224494934082\n",
      "####################################################################################\n",
      "Alpha: Parameter containing:\n",
      "tensor(0.0268, requires_grad=True)\n",
      "Beta: Parameter containing:\n",
      "tensor(0.0245, requires_grad=True)\n",
      "Evaluate Result:\n",
      "Epoch-017     8 Batches, Step    144, Testing Loss:  0.187897, Used Time:   0.2m, Remaining Time:   0.0m\n",
      "-------------------------------------------------------------------------------\n",
      "Best Metric: 0.1878967359662056\n",
      "####################################################################################\n",
      "Alpha: Parameter containing:\n",
      "tensor(0.0280, requires_grad=True)\n",
      "Beta: Parameter containing:\n",
      "tensor(0.0274, requires_grad=True)\n",
      "Evaluate Result:\n",
      "Epoch-018     8 Batches, Step    152, Testing Loss:  0.210381, Used Time:   0.2m, Remaining Time:   0.0m\n",
      "-------------------------------------------------------------------------------\n",
      "Best Metric: 0.1878967359662056\n",
      "####################################################################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha: Parameter containing:\n",
      "tensor(0.0292, requires_grad=True)\n",
      "Beta: Parameter containing:\n",
      "tensor(0.0309, requires_grad=True)\n",
      "Evaluate Result:\n",
      "Epoch-019     8 Batches, Step    160, Testing Loss:  0.180295, Used Time:   0.2m, Remaining Time:   0.0m\n",
      "-------------------------------------------------------------------------------\n",
      "Best Metric: 0.18029461101609834\n",
      "####################################################################################\n",
      "Final Best Metric: 0.18029461101609834\n",
      "Final metrics: 0.1802946\n"
     ]
    }
   ],
   "source": [
    "!python main.py -data data_offline -batch_size 512 -plot_title 'paper_0201' \\\n",
    "-max_epoch 20 -lr 1e-3 -opt Adam -test_batch_size 100 -model deepgbm \\\n",
    "-task regression -l2_reg 1e-6 -test_freq 300 -seed 1,2,3,4,5 -group_method Random \\\n",
    "-emb_epoch 2 -loss_de 2 -loss_dr 0.7 -tree_lr 0.1 -cate_layers 16,16 -nslices 5 \\\n",
    " -tree_layers 100,100,100,50 -embsize 20 -maxleaf 64 -log_freq 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "DeepGBM_other.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
